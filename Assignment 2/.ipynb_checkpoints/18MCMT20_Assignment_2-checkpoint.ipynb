{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8J_oeH4WcHmB"
   },
   "source": [
    "# NN Assignent - 2\n",
    "<b>\n",
    "<p >Assignment No: 2</p>\n",
    "<p >Name : Krutika Injamuri</p>\n",
    "<p >Roll No:18MCMT20</p>\n",
    "<p>Brach: MTech CS</p>\n",
    "</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "tHy46ogZcrQe",
    "outputId": "802a1dad-bd0d-4e18-af92-25a0911273bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 53688\n",
      "drwxr-xr-x 1 root root     4096 Oct  8 07:25 .\n",
      "drwxr-xr-x 1 root root     4096 Oct  7 13:02 ..\n",
      "drwxr-xr-x 4 root root     4096 Sep 28 23:11 .config\n",
      "drwxr-xr-x 2 root root     4096 Sep 28 23:32 sample_data\n",
      "-rw-r--r-- 1 root root  7840016 Oct  8 07:25 t10k-images.idx3-ubyte\n",
      "-rw-r--r-- 1 root root    10008 Oct  8 07:22 t10k-labels.idx1-ubyte\n",
      "-rw-r--r-- 1 root root 47040016 Oct  8 07:41 train-images.idx3-ubyte\n",
      "-rw-r--r-- 1 root root    60008 Oct  8 07:25 train-labels.idx1-ubyte\n"
     ]
    }
   ],
   "source": [
    "!ls -al"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 242,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "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",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": ""
      }
     }
    },
    "colab_type": "code",
    "id": "_P7_wwx9YAt5",
    "outputId": "c77ff9d2-d95a-4da5-d61b-496f842a07f5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-2425ba3a-4b70-4051-8f1f-9fcd70761bed\" name=\"files[]\" multiple disabled />\n",
       "     <output id=\"result-2425ba3a-4b70-4051-8f1f-9fcd70761bed\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving t10k-labels.idx1-ubyte to t10k-labels.idx1-ubyte\n",
      "Saving t10k-images.idx3-ubyte to t10k-images.idx3-ubyte\n",
      "Saving train-labels.idx1-ubyte to train-labels.idx1-ubyte\n",
      "Saving train-images.idx3-ubyte to train-images.idx3-ubyte\n",
      "User uploaded file \"t10k-labels.idx1-ubyte\" with length 10008 bytes\n",
      "User uploaded file \"t10k-images.idx3-ubyte\" with length 7840016 bytes\n",
      "User uploaded file \"train-labels.idx1-ubyte\" with length 60008 bytes\n",
      "User uploaded file \"train-images.idx3-ubyte\" with length 47040016 bytes\n"
     ]
    }
   ],
   "source": [
    "from google.colab import files\n",
    "import io\n",
    "from google.colab import files\n",
    "uploaded = files.upload()\n",
    "\n",
    "for fn in uploaded.keys():\n",
    "  print('User uploaded file \"{name}\" with length {length} bytes'.format(name=fn, length=len(uploaded[fn])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cWwywd-DZtkC"
   },
   "source": [
    "**Imports Used throughout assignment:**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wkcrilnxZsAR"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import struct as st\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "from scipy.ndimage import interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "id": "531BuTd_TtU_",
    "outputId": "e8c13177-4a8a-4987-8f8b-d770b7a8cece"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data is  3 -D\n",
      "no. of images ::  60000\n",
      "no. of rows ::  28\n",
      "no. of columns ::  28\n",
      "no. of images test ::  10000\n",
      "no. of rows test::  28\n",
      "no. of columns test::  28\n",
      "Time of execution : 4.762466669082642 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "stime = time.time()\n",
    "filename = {'images' : 'train-images.idx3-ubyte' ,'labels' : 'train-labels.idx1-ubyte','testImages' : 't10k-images.idx3-ubyte' ,'testLabels' : 't10k-labels.idx1-ubyte'}\n",
    "\n",
    "labels_array = np.array([])\n",
    "\n",
    "data_types = {\n",
    "        0x08: ('ubyte', 'B', 1),\n",
    "        0x09: ('byte', 'b', 1),\n",
    "        0x0B: ('>i2', 'h', 2),\n",
    "        0x0C: ('>i4', 'i', 4),\n",
    "        0x0D: ('>f4', 'f', 4),\n",
    "        0x0E: ('>f8', 'd', 8)}\n",
    "\n",
    "for name in filename.keys():\n",
    "    if name == 'images':\n",
    "        imagesfile = open(filename[name],'rb')\n",
    "    if name == 'labels':\n",
    "        labelsfile = open(filename[name],'rb')\n",
    "    if name == 'testImages':\n",
    "        testImagesFile = open(filename[name],'rb')\n",
    "    if name == 'testLabels':\n",
    "        testLabelsFile = open(filename[name],'rb')\n",
    "\n",
    "        \n",
    "def getParams(file):\n",
    "  file.seek(4)\n",
    "  nImg = st.unpack('>I',file.read(4))[0] #num of images/labels\n",
    "  nR = st.unpack('>I',file.read(4))[0] #num of rows\n",
    "  nC = st.unpack('>I',file.read(4))[0] #num of columns\n",
    "  return nImg,nR,nC\n",
    "  \n",
    "#reading magic number\n",
    "imagesfile.seek(0)\n",
    "magic = st.unpack('>4B',imagesfile.read(4))\n",
    "\n",
    "# print(magic)\n",
    "if(magic[0] and magic[1])or(magic[2] not in data_types):\n",
    "    raise ValueError(\"File Format not correct\")\n",
    "\n",
    "nDim = magic[3]\n",
    "print(\"Data is \",nDim,\"-D\")\n",
    "\n",
    "\n",
    "nImg,nR,nC= getParams(imagesfile)\n",
    "nBytes = nImg*nR*nC\n",
    "labelsfile.seek(8) #Since no. of items = no. of images and is already read\n",
    "print(\"no. of images :: \",nImg)\n",
    "print(\"no. of rows :: \",nR)\n",
    "print(\"no. of columns :: \",nC)\n",
    "\n",
    "\n",
    "nImgTest,nRTest,nCTest= getParams(testImagesFile)\n",
    "nBytesTest = nImgTest*nRTest*nCTest\n",
    "testLabelsFile.seek(8) #Since no. of items = no. of images and is already read\n",
    "print(\"no. of images test :: \",nImgTest)\n",
    "print(\"no. of rows test:: \",nRTest)\n",
    "print(\"no. of columns test:: \",nCTest)\n",
    "\n",
    "\n",
    "#Read all data bytes at once and then reshape\n",
    "normalizingValue=(255  *0.99 + 0.01)\n",
    "train_imgs = np.asarray(st.unpack('>'+'B'*nBytes,imagesfile.read(nBytes))).reshape((nImg,nR*nC))\n",
    "train_labels = np.asarray(st.unpack('>'+'B'*nImg,labelsfile.read(nImg))).reshape((nImg,1))\n",
    "\n",
    "test_imgs = np.asarray(st.unpack('>'+'B'*nBytesTest,testImagesFile.read(nBytesTest))).reshape((nImgTest,nRTest*nCTest))\n",
    "test_labels = np.asarray(st.unpack('>'+'B'*nImgTest,testLabelsFile.read(nImgTest))).reshape((nImgTest,1))\n",
    "# images_array=np.true_divide(images_array,normalizingValue)\n",
    "# test_images_array=np.true_divide(test_images_array,normalizingValue)\n",
    "\n",
    "\n",
    "lr = np.arange(10)\n",
    "# transform labels into one hot representation\n",
    "train_labels_one_hot = (lr==train_labels).astype(np.float)\n",
    "test_labels_one_hot = (lr==test_labels).astype(np.float)\n",
    "# we don't want zeroes and ones in the labels neither:\n",
    "train_labels_one_hot[train_labels_one_hot==0] = 0.01\n",
    "train_labels_one_hot[train_labels_one_hot==1] = 0.99\n",
    "test_labels_one_hot[test_labels_one_hot==0] = 0.01\n",
    "test_labels_one_hot[test_labels_one_hot==1] = 0.99\n",
    "\n",
    "train_imgs=0.99 - (((0.98) * (255 - train_imgs)) / 255)\n",
    "test_imgs=0.99 - (((0.98) * (255 - test_imgs)) / 255)\n",
    "\n",
    "\n",
    "no_of_different_labels = 10 \n",
    "image_size=28\n",
    "image_pixels = image_size * image_size\n",
    "print(\"Time of execution : %s seconds\" % str(time.time()-stime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uCx_B0IAGhwN"
   },
   "outputs": [],
   "source": [
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.e ** -x)\n",
    "def sigDerivative(x):\n",
    "  return x*(1-x)\n",
    "  \n",
    "activation_function = sigmoid\n",
    "\n",
    "class NeuralNetwork:\n",
    "    \n",
    "    def __init__(self,inNodes, outNodes, hiddenNodes,learningRate,epochs):\n",
    "      self.inNodes = inNodes\n",
    "      self.outNodes = outNodes\n",
    "      self.hiddenNodes = hiddenNodes\n",
    "      self.learningRate = learningRate \n",
    "      self.itohweights=np.random.randn(self.hiddenNodes, self.inNodes)\n",
    "      self.htooweights=np.random.randn(self.outNodes, self.hiddenNodes)\n",
    "      self.itohchangeWeights=np.random.randn(self.hiddenNodes, self.inNodes)\n",
    "      self.htoochangeWeights=np.random.randn(self.outNodes, self.hiddenNodes)\n",
    "      self.xj=[]\n",
    "      self.epochs=epochs\n",
    "        \n",
    "    def forwardPropagation(self,inputVector):\n",
    "      inputVector = np.array(inputVector, ndmin=2).T\n",
    "\n",
    "      output_vector1 = np.dot(self.itohweights, inputVector)\n",
    "      self.xj = sigmoid(output_vector1)\n",
    "\n",
    "      output_vector2 = np.dot(self.htooweights,self.xj)\n",
    "      return sigmoid(output_vector2)\n",
    "      \n",
    "    def backPropagation(self,inputVector,targetVector,expectedVector,regularization):\n",
    "        targetVector = np.array(targetVector, ndmin=2).T\n",
    "        inputVector = np.array(inputVector, ndmin=2).T\n",
    "      \n",
    "        errors = targetVector - expectedVector\n",
    "        tmp = errors * sigDerivative(expectedVector )\n",
    "        if regularization == None:\n",
    "          self.htooweights += self.learningRate  * np.dot(tmp,self.xj.T)\n",
    "        else:\n",
    "          self.htooweights += self.learningRate  * np.dot(tmp,self.xj.T) + 0.0001*self.htoochangeWeights\n",
    "          self.htoochangeWeights=np.dot(tmp,self.xj.T)\n",
    "        \n",
    "        # calculate hidden errors:\n",
    "        hidden_errors = np.dot(self.htooweights.T,errors)\n",
    "        # update the weights:\n",
    "        tmp = hidden_errors * sigDerivative(self.xj)\n",
    "        if regularization == None:\n",
    "          self.itohweights += self.learningRate * np.dot(tmp, inputVector.T)\n",
    "\n",
    "        else:\n",
    "          self.itohweights += self.learningRate * np.dot(tmp, inputVector.T) + 0.0001*self.itohchangeWeights\n",
    "          self.itohchangeWeights=np.dot(tmp, inputVector.T)\n",
    "      \n",
    "    \n",
    "    def train(self, inputVector, targetVector,reg):\n",
    "        for ep in range(self.epochs):\n",
    "          self.backPropagation(inputVector,targetVector,self.forwardPropagation(inputVector),reg)\n",
    "          \n",
    "          \n",
    "    def run(self, inputVector):\n",
    "       \n",
    "        return self.forwardPropagation(inputVector)\n",
    "            \n",
    "    def confusion_matrix(self, data_array, labels):\n",
    "        cm = np.zeros((10, 10), int)\n",
    "        for i in range(len(data_array)):\n",
    "            res = self.run(data_array[i])\n",
    "            res_max = res.argmax()\n",
    "            target = labels[i][0]\n",
    "            cm[res_max, int(target)] += 1\n",
    "        return cm   \n",
    "    def evaluate(self, data, labels):\n",
    "      corrects, wrongs = 0, 0\n",
    "      for i in range(len(data)):\n",
    "          res = self.run(data[i])\n",
    "          res_max = res.argmax()\n",
    "          if res_max == labels[i]:\n",
    "              corrects += 1\n",
    "          else:\n",
    "              wrongs += 1\n",
    "      return corrects, wrongs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NNKMIIb-JgMP"
   },
   "outputs": [],
   "source": [
    "class measuresOfConMatrix:\n",
    "  def __init__(self,cm):\n",
    "    self.cm=cm\n",
    "    self.TP=self.getTP()\n",
    "    self.TN=self.getTN()\n",
    "    self.FP=self.getFP()\n",
    "    self.FN=self.getFN()\n",
    "    self.tot=self.TP+self.TN+self.FP+self.FN\n",
    "  def errorRate(self):\n",
    "    return np.around(((self.FP+self.FN)/self.tot),decimals=3)\n",
    "\n",
    "  def accuracy(self):\n",
    "    return np.around((self.TP+self.TN)/self.tot,decimals=3)\n",
    "\n",
    "  def precision(self):\n",
    "    return np.around((self.TP/(self.TP+self.FP)),decimals=3)\n",
    "  def recall(self):\n",
    "    return np.around((self.TP/(self.TP+self.FN)),decimals=3)\n",
    "  def specificity(self):\n",
    "    return np.around((self.TN/(self.FP+self.TN)),decimals=3)\n",
    "\n",
    "  def getTP(self):\n",
    "        return np.diag(self.cm)\n",
    "  def getFP(self):\n",
    "      FP = []\n",
    "      for i in range(10):\n",
    "        FP.append(sum(self.cm[:,i]) - self.cm[i,i])\n",
    "      return np.array(FP)\n",
    "  def getFN(self):  \n",
    "      FN = []\n",
    "      for i in range(10):\n",
    "          FN.append(sum(self.cm[i,:]) - self.cm[i,i])\n",
    "      return np.array(FN)\n",
    "  def getTN(self):\n",
    "      TN = []\n",
    "      for i in range(10):\n",
    "          temp = np.delete(self.cm, i, 0)   # delete ith row\n",
    "          temp = np.delete(temp, i, 1)  # delete ith column\n",
    "          TN.append(sum(sum(temp)))\n",
    "      return np.array(TN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4ses2A4FfkuK"
   },
   "source": [
    "**5 FoldCross Validation:**\n",
    "\n",
    " In the below we are doing a 5 fold cross validation. The entire data set is divided into 5 equal partions. In each iteration we consider 4 sets as the training sets and remaining set as the test set. Over these training and test sets the model is trained and tested. Each time error is calculated. This is called as the cross validation error. Average is found of these error values.\n",
    " \n",
    " The above process is repeated for different models and the one with the least average error is chosen. This model is then used to train the entire dataset and then test it. \n",
    " \n",
    " This process of cross validations allows us to choose the best model with least average error.\n",
    " \n",
    " In the below code Stochaistic Gradient odel is used with different hyper parameters in each Cross Validation.\n",
    " \n",
    " **Observations:**\n",
    "\n",
    "1.  As the number of hidden unit increases the time taken to execute also increases\n",
    "2.   As the chosen model is Stochaistic Gradient descent, it updates the weight matrix for each of the epoch and hence the time consumed is more.\n",
    "3. The minimum cross validation average error is **0.17984**\n",
    "\n",
    "**Confusion Matrix:**\n",
    "\n",
    "It is a 10 x 10 matrix, where the rows represent the true label of a test sample and the columnsrepresent the predicted labels of the NN classifier\n",
    "\n",
    "There are many measures of Confusion matrix like error, accuracy, standard deviation and many more.\n",
    "\n",
    "TP: True Positive\n",
    "TN: True Negative\n",
    "FP: False Positive\n",
    "FP: False Negative\n",
    "\n",
    "Error = (FP+FN)/(TP+TN+FP+FN)\n",
    "\n",
    "Accuracy = (TP+TN)/(TP+TN+FP+FN)\n",
    "\n",
    "Sensitivity/Recall = TP/(TP+FN)\n",
    "\n",
    "Specificity = TN/(FP+TN)\n",
    "\n",
    "Precision =  TP/(TP+FP)\n",
    "\n",
    "Below are the observations for the best model used\n",
    "Model  Used :  Stochastic Gradient descent Model\n",
    "\n",
    "Hyper Parameters:\n",
    "\n",
    "$\\eta $=0.01, \n",
    "number of hidden layers = 1, \n",
    "number of hidden nodes in one layer = 100, \n",
    "number of epochs = 1\n",
    "\n",
    "**Confusion Matrix obtained:**\n",
    "\n",
    "$\\left[ \\begin{array}{cccc}\n",
    " 956&0& 12&4&0& 10&8&2&4&4\\\\\n",
    "1& 1121&6&6&0&6&4& 18& 10& 11\\\\\n",
    "2&2&934&6&5&4&2& 16&7&0\\\\\n",
    "1&3& 17&932&0& 43&0&7& 12& 15\\\\\n",
    "0&0& 11&3&888&8&7&8&5& 11\\\\\n",
    "2&1&1&6&0&747&9&1&4&0\\\\\n",
    "7&4& 13&3& 10& 10&917&1&4&1\\\\\n",
    "2&1&7&5&0&3&0&923&4&4\\\\\n",
    "7&3& 27& 33& 13& 44& 11&4&905& 11\\\\\n",
    "2&0&4& 12& 66& 17&0& 48& 19&952\\\\\\\\\n",
    "\\end{array} \\right]$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**Total Accuracy:** 86.96%\n",
    "\n",
    "** Total Error: ** 13.0999%\n",
    "\n",
    "**Average Error of all folds in Cross Validation: **   0.17968\n",
    " \n",
    " \n",
    " **Average Error of digits:** 2.61%\n",
    " **Average Standard Deviation:**  0.00938562730988185\n",
    " \n",
    "\n",
    " | Digit | Precision|Recall|Accuracy | Specificity |Error\n",
    "|------|------|------|------|------|------|\n",
    "| 0 |  0.976 |  0.956 |  0.993 |  0.997 |0.007\n",
    "| 1 |  0.988 |  0.948 |  0.992 |  0.998 |0.008\n",
    "| 2 |  0.905 |  0.955 |  0.986 |  0.989 |0.014\n",
    "| 3 |  0.923 |  0.905 |  0.982 |  0.991 |0.018\n",
    "| 4 |  0.904 |  0.944 |  0.985 |  0.99 |0.015\n",
    "| 5 |  0.837 |  0.969 |  0.983 |  0.984 |0.017\n",
    "| 6 |  0.957 |  0.945 |  0.991 |  0.995 |0.009\n",
    "| 7 |  0.898 |  0.973 |  0.987 |  0.988 |0.013\n",
    "| 8 |  0.929 |  0.855 |  0.978 |  0.992 |0.022\n",
    "| 9 |  0.944 |  0.85 |  0.978 |  0.994 |0.022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 918
    },
    "colab_type": "code",
    "id": "BPP6A_87TV3P",
    "outputId": "368bbbcb-bd0d-4300-da0d-0b7b4f183e51"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------START----------------------------------------\n",
      "hiddenNodes :  100 learningRate =  0.1 epochs=  1\n",
      "Error at folds :  [0.17930000000000001, 0.1791, 0.1804, 0.17960000000000004, 0.18080000000000002]\n",
      "Average Error :  0.17984000000000006\n",
      "-----------------------------------END----------------------------------------\n",
      "-----------------------------------START----------------------------------------\n",
      "hiddenNodes :  100 learningRate =  0.1 epochs=  5\n",
      "Error at folds :  [0.17990000000000003, 0.1799, 0.1804, 0.181, 0.18120000000000003]\n",
      "Average Error :  0.18048000000000003\n",
      "-----------------------------------END----------------------------------------\n",
      "-----------------------------------START----------------------------------------\n",
      "hiddenNodes :  150 learningRate =  0.1 epochs=  1\n",
      "Error at folds :  [0.18010000000000004, 0.17930000000000001, 0.18080000000000002, 0.18040000000000003, 0.18180000000000002]\n",
      "Average Error :  0.18048000000000003\n",
      "-----------------------------------END----------------------------------------\n",
      "-----------------------------------START----------------------------------------\n",
      "hiddenNodes :  150 learningRate =  0.1 epochs=  5\n",
      "Error at folds :  [0.1797, 0.17950000000000005, 0.18120000000000003, 0.1806, 0.18100000000000002]\n",
      "Average Error :  0.18040000000000003\n",
      "-----------------------------------END----------------------------------------\n",
      "-----------------------------------START----------------------------------------\n",
      "hiddenNodes :  200 learningRate =  0.1 epochs=  1\n",
      "Error at folds :  [0.18000000000000002, 0.1802, 0.18040000000000003, 0.1806, 0.18080000000000002]\n",
      "Average Error :  0.18040000000000003\n",
      "-----------------------------------END----------------------------------------\n",
      "-----------------------------------START----------------------------------------\n",
      "hiddenNodes :  200 learningRate =  0.1 epochs=  5\n",
      "Error at folds :  [0.18020000000000003, 0.18140000000000003, 0.18109999999999998, 0.1799, 0.1809]\n",
      "Average Error :  0.1807\n",
      "-----------------------------------END----------------------------------------\n",
      "Min Error Index :  0 Min Error :  0.17984000000000006\n",
      "Model Used:  [100, 0.1, 1]\n",
      "[[ 956    0   12    4    0   10    8    2    4    4]\n",
      " [   1 1121    6    6    0    6    4   18   10   11]\n",
      " [   2    2  934    6    5    4    2   16    7    0]\n",
      " [   1    3   17  932    0   43    0    7   12   15]\n",
      " [   0    0   11    3  888    8    7    8    5   11]\n",
      " [   2    1    1    6    0  747    9    1    4    0]\n",
      " [   7    4   13    3   10   10  917    1    4    1]\n",
      " [   2    1    7    5    0    3    0  923    4    4]\n",
      " [   7    3   27   33   13   44   11    4  905   11]\n",
      " [   2    0    4   12   66   17    0   48   19  952]]\n",
      "digit:  0 Precision:  0.976 Recall:  0.956 Accuracy:  0.993 Specificity:  0.997 errorRate:  0.007\n",
      "digit:  1 Precision:  0.988 Recall:  0.948 Accuracy:  0.992 Specificity:  0.998 errorRate:  0.008\n",
      "digit:  2 Precision:  0.905 Recall:  0.955 Accuracy:  0.986 Specificity:  0.989 errorRate:  0.014\n",
      "digit:  3 Precision:  0.923 Recall:  0.905 Accuracy:  0.982 Specificity:  0.991 errorRate:  0.018\n",
      "digit:  4 Precision:  0.904 Recall:  0.944 Accuracy:  0.985 Specificity:  0.99 errorRate:  0.015\n",
      "digit:  5 Precision:  0.837 Recall:  0.969 Accuracy:  0.983 Specificity:  0.984 errorRate:  0.017\n",
      "digit:  6 Precision:  0.957 Recall:  0.945 Accuracy:  0.991 Specificity:  0.995 errorRate:  0.009\n",
      "digit:  7 Precision:  0.898 Recall:  0.973 Accuracy:  0.987 Specificity:  0.988 errorRate:  0.013\n",
      "digit:  8 Precision:  0.929 Recall:  0.855 Accuracy:  0.978 Specificity:  0.992 errorRate:  0.022\n",
      "digit:  9 Precision:  0.944 Recall:  0.85 Accuracy:  0.978 Specificity:  0.994 errorRate:  0.022\n",
      "Accuracy :  0.9275 Total Error :  0.07250000000000001 Average error:  0.014499999999999999 Average Standar Deviation of Error Rate: 0.005123475382979799\n"
     ]
    }
   ],
   "source": [
    "train_imgs=train_imgs.reshape(nImg,nR*nC)\n",
    "\n",
    "test_imgs=test_imgs.reshape(nImgTest,nRTest*nCTest)\n",
    "numberOfFolds=5\n",
    "hyperParameters=[[100,0.1,1],[100,0.1,5],[150,0.1,1],[150,0.1,5],[200,0.1,1],[200,0.1,5]]\n",
    "# hyperParameters=[[100,0.1,1,100],[100,0.1,1,200],[100,0.1,1,300],[100,0.1,1,400],[100,0.1,1,500],[100,0.1,1,600],[100,0.1,1,00],]\n",
    "\n",
    "errorTracker=[]\n",
    "stdTracker=[]\n",
    "avgErrorTracker=[]\n",
    "minErrorIndex=0\n",
    "minError=10000\n",
    "\n",
    "for index in range(len(hyperParameters)):\n",
    "  print(\"-----------------------------------START----------------------------------------\")\n",
    "  kfold = KFold(numberOfFolds,False, 1)\n",
    "  print(\"hiddenNodes : \", hyperParameters[index][0], \"learningRate = \",hyperParameters[index][1],\"epochs= \",hyperParameters[index][2])\n",
    "  foldError=[]\n",
    "  stdError=[]\n",
    "  for train, test in kfold.split(train_imgs):\n",
    "    nn = NeuralNetwork(inNodes = image_pixels, outNodes = 10,  hiddenNodes = hyperParameters[index][0], learningRate = hyperParameters[index][1],epochs=hyperParameters[index][2])\n",
    "    trainingSetImg=train_imgs[train]\n",
    "    testingSetImg=train_imgs[test]   \n",
    "    trainingSetLabel=train_labels_one_hot[train]\n",
    "    testingSetLabel=train_labels_one_hot[test]\n",
    "    for k in range(trainingSetImg.shape[0]):\n",
    "      nn.train(trainingSetImg[k], trainingSetLabel[k],None)\n",
    "    cm = nn.confusion_matrix(testingSetImg, testingSetLabel)\n",
    "\n",
    "    conMatrixMeasures=measuresOfConMatrix(cm)\n",
    "    foldError.append(np.average(conMatrixMeasures.errorRate()))\n",
    "    stdError.append(np.std(conMatrixMeasures.errorRate()))\n",
    "  print(\"Error at folds : \",foldError)\n",
    "  errorTracker.append(foldError)\n",
    "  stdTracker.append(stdError)\n",
    "  avgError=np.average(foldError)\n",
    "  print(\"Average Error : \",avgError)\n",
    "  avgErrorTracker.append(avgError)\n",
    "  if(avgError<minError):\n",
    "    minError=avgError\n",
    "    minErrorIndex=index\n",
    "  print(\"-----------------------------------END----------------------------------------\")\n",
    "   \n",
    "print(\"Min Error Index : \",minErrorIndex,\"Min Error : \",minError)\n",
    "print(\"Model Used: \",hyperParameters[minErrorIndex])    \n",
    "nn = NeuralNetwork(inNodes = image_pixels, outNodes = 10,  hiddenNodes = hyperParameters[minErrorIndex][0], learningRate = hyperParameters[minErrorIndex][1],epochs=hyperParameters[minErrorIndex][2])   \n",
    "for i in range(train_imgs.shape[0]):\n",
    "  nn.train(train_imgs[i],train_labels_one_hot[i],None)\n",
    "cm=nn.confusion_matrix(test_imgs, test_labels)\n",
    "print(cm)\n",
    "conMatrixMeasures=measuresOfConMatrix(cm)\n",
    "corrects, wrongs = nn.evaluate(test_imgs, test_labels)\n",
    "accuracy=corrects / ( corrects + wrongs)\n",
    "for i in range(10):\n",
    "  print(\"digit: \", i, \"Precision: \", conMatrixMeasures.precision()[i], \"Recall: \", conMatrixMeasures.recall()[i],\n",
    "       \"Accuracy: \", conMatrixMeasures.accuracy()[i], \"Specificity: \", conMatrixMeasures.specificity()[i],\n",
    "       \"errorRate: \",conMatrixMeasures.errorRate()[i])\n",
    "print(\"Accuracy : \",accuracy,\"Total Error : \",1-accuracy,\"Average error: \",np.average(conMatrixMeasures.errorRate()),\"Average Standar Deviation of Error Rate:\",np.std(conMatrixMeasures.errorRate()));\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 715
    },
    "colab_type": "code",
    "id": "V7VqiYWOUKCH",
    "outputId": "dddea7c8-5065-40b1-81d2-bfc65ddd80fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error at each fold : [0.17930000000000001, 0.1791, 0.1804, 0.17960000000000004, 0.18080000000000002]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe8AAAFOCAYAAACvyZWGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAG9dJREFUeJzt3X9MVffh//HXtZQoXDqB3stqMvqD\nqhAMnSRriugqFNbUxna6eL2lwsyaJaatWFpWzJ0FOiN+y/ZdVtTUtrplmZreVW9XPkk73PrRZmmu\nENMGI1vTW0KI1QL3Vn5IEWqVzx9Nz6Qi99Ci8Ibn4y/OPT98n/etfd57rvfgGB4eHhYAADDGrMke\nAAAAGB/iDQCAYYg3AACGId4AABiGeAMAYBjiDQCAYWLsbFRTU6Pm5mY5HA75fD5lZWVZ64aGhlRZ\nWalQKKRAICBJ+vzzz1VRUaHe3l5duHBBTzzxhJYtW6bi4mINDAwoLi5OklRRUaFFixZdg9MCAGD6\nihrvpqYmtbe3y+/3q7W1VT6fT36/31pfW1urjIwMhUIh67E33nhDt99+u5555hl1dnbq5z//uf7+\n979LkrZv364FCxZcg1MBAGBmiHrZPBgMqqCgQJKUlpam3t5e9ff3W+vLysqs9V9LTExUT0+PJKmv\nr0+JiYkTOWYAAGa0qO+8I5GIMjMzreWkpCSFw2E5nU5JktPptEL9tQcffFCBQECFhYXq6+vTyy+/\nbK2rq6tTd3e30tLS5PP5NHv27Ik6FwAAZoRx/4M1O3dTffPNNzVv3jz94x//0J///Gf95je/kSSV\nlJTo2Wef1f79++VwOLR///7v/GcBADDTRH3n7Xa7FYlErOWuri65XK4x93n//fe1dOlSSVJ6erq6\nurp08eJFFRYWWtvk5+frrbfeGvM4DodD4fC5aEOEJJcrgbmygXmyj7myh3myh3myz+VKiLpN1Hfe\nubm5amhokCS1tLTI7XZbl8yv5tZbb1Vzc7Mk6fTp04qPj9esWbO0fv169fX1SZIaGxs1f/78qAME\nAAAjRX3nnZ2drczMTHm9XjkcDlVVVSkQCCghIUGFhYUqLS1VR0eH2traVFxcLI/Ho7Vr18rn82nd\nunX68ssvVV1dLYfDIY/Ho/Xr12vOnDlKSUnRxo0br8c5AgAwrTim+q8E5TKLPVySsod5so+5sod5\nsod5sm9CLpsDAICphXgDAGAY4g0AgGGINwAAhiHeAAAYhngDAGAY4g0AgGGINwAAhiHeAAAYhngD\nAGAY4g0AgGGINwAAhiHeAAAYhngDAGAY4g0AgGGINwAAhiHeAAAYhngDAGAY4g0AgGGINwAAhiHe\nAAAYhngDAGAY4g0AgGGINwAAhiHeAAAYhngDAGAY4g0AgGGINwAAhiHeAAAYhngDAGAY4g0AgGFi\nJnsAAIDr6xf/738newjXzR8350/2EK4J3nkDAGAY4g0AgGFsXTavqalRc3OzHA6HfD6fsrKyrHVD\nQ0OqrKxUKBRSIBCQJH3++eeqqKhQb2+vLly4oCeeeELLli3Thx9+qOrqaknSwoUL9fzzz0/8GQHT\nDJc4AXxT1HfeTU1Nam9vl9/v17Zt27Rt27YR62tra5WRkTHisTfeeEO33367/vKXv+jFF1+09tm2\nbZt8Pp9ee+019ff36913353AUwEAYGaIGu9gMKiCggJJUlpamnp7e9Xf32+tLysrs9Z/LTExUT09\nPZKkvr4+JSYm6osvvtDp06etd+15eXkKBoMTdiIAAMwUUeMdiUSUmJhoLSclJSkcDlvLTqfzin0e\nfPBBnTlzRoWFhVq3bp0qKirU3d2tm266ydomOTl5xHEAAIA94/6q2PDwcNRt3nzzTc2bN0979+7V\nhx9+KJ/Pp5deemncx5EklythvEOcsZgre5inqcvU58bUcc8E0/W5iRpvt9utSCRiLXd1dcnlco25\nz/vvv6+lS5dKktLT09XV1TXiUrokdXZ2yu12Rx1gOHwu6jb46j9Q5io65mlqM/G54b+pqc3E58bO\nC46ol81zc3PV0NAgSWppaZHb7R71Uvnlbr31VjU3N0uSTp8+rfj4eMXGxuqOO+7Q8ePHJUmHDx/W\nsmXLog4QAACMFPWdd3Z2tjIzM+X1euVwOFRVVaVAIKCEhAQVFhaqtLRUHR0damtrU3FxsTwej9au\nXSufz6d169bpyy+/tL4e5vP5VFlZqUuXLumuu+7SkiVLrvX5AZghZtJX6iS+VjfT2frMu7y8fMRy\nenq69XNdXd2o+7z44otXPHbnnXfqwIED4xkfAAD4Bu6wBgCAYfjFJBOMS3cAgGuNeGNS8CIHAL49\nLpsDAGAY4g0AgGGINwAAhiHeAAAYhngDAGAY4g0AgGGINwAAhiHeAAAYhngDAGAY4g0AgGGINwAA\nhiHeAAAYhngDAGAY4g0AgGGINwAAhiHeAAAYhngDAGAY4g0AgGGINwAAhiHeAAAYhngDAGAY4g0A\ngGGINwAAhiHeAAAYhngDAGAY4g0AgGGINwAAhiHeAAAYhngDAGAY4g0AgGGINwAAhomxs1FNTY2a\nm5vlcDjk8/mUlZVlrRsaGlJlZaVCoZACgYAk6fXXX1d9fb21zcmTJ/XBBx+ouLhYAwMDiouLkyRV\nVFRo0aJFE3k+AABMe1Hj3dTUpPb2dvn9frW2tsrn88nv91vra2trlZGRoVAoZD22Zs0arVmzxtr/\n7bffttZt375dCxYsmMhzAABgRol62TwYDKqgoECSlJaWpt7eXvX391vry8rKrPWj2bVrlx5//PEJ\nGCoAAJBsvPOORCLKzMy0lpOSkhQOh+V0OiVJTqdTPT09o+574sQJ3XLLLXK5XNZjdXV16u7uVlpa\nmnw+n2bPnj3mn+9yJdg6EUwOnh97mCd7mCf7mCt7pus82frM+3LDw8O2tz148KBWrVplLZeUlGjh\nwoVKTU1VVVWV9u/fr8cee2zMY4TD58Y7RFxHPD/2ME/2ME/2MVf2mDhPdl5wRL1s7na7FYlErOWu\nrq4R76TH0tjYqMWLF1vLhYWFSk1NlSTl5+fro48+snUcAADwX1HjnZubq4aGBklSS0uL3G63dcl8\nLJ2dnYqPj1dsbKykr96xr1+/Xn19fZK+Cvv8+fO/y9gBAJiRol42z87OVmZmprxerxwOh6qqqhQI\nBJSQkKDCwkKVlpaqo6NDbW1tKi4ulsfj0cqVKxUOh5WUlGQdx+FwyOPxaP369ZozZ45SUlK0cePG\na3pyAABMR7Y+8y4vLx+xnJ6ebv1cV1c36j6LFi3Snj17Rjy2YsUKrVixYrxjBAAAl+EOawAAGIZ4\nAwBgGOINAIBhiDcAAIYh3gAAGIZ4AwBgGOINAIBhiDcAAIYh3gAAGIZ4AwBgGOINAIBhiDcAAIYh\n3gAAGIZ4AwBgGOINAIBhiDcAAIYh3gAAGIZ4AwBgGOINAIBhiDcAAIYh3gAAGIZ4AwBgGOINAIBh\niDcAAIYh3gAAGIZ4AwBgGOINAIBhiDcAAIYh3gAAGIZ4AwBgGOINAIBhiDcAAIYh3gAAGCbGzkY1\nNTVqbm6Ww+GQz+dTVlaWtW5oaEiVlZUKhUIKBAKSpNdff1319fXWNidPntQHH3ygDz/8UNXV1ZKk\nhQsX6vnnn5/AUwEAYGaIGu+mpia1t7fL7/ertbVVPp9Pfr/fWl9bW6uMjAyFQiHrsTVr1mjNmjXW\n/m+//bYkadu2bVb8n3nmGb377ru69957J/qcAACY1qJeNg8GgyooKJAkpaWlqbe3V/39/db6srIy\na/1odu3apccff1xffPGFTp8+bb1rz8vLUzAY/K7jBwBgxoka70gkosTERGs5KSlJ4XDYWnY6nVfd\n98SJE7rlllvkcrnU3d2tm266yVqXnJw84jgAAMAeW595X254eNj2tgcPHtSqVau+03FcrgTbfx6u\nP54fe5gne5gn+5gre6brPEWNt9vtViQSsZa7urrkcrlsHbyxsVFbtmyR9NU79p6eHmtdZ2en3G53\n1GOEw+ds/VmYHDw/9jBP9jBP9jFX9pg4T3ZecES9bJ6bm6uGhgZJUktLi9xu95iXyr/W2dmp+Ph4\nxcbGSpJuvPFG3XHHHTp+/Lgk6fDhw1q2bFnU4wAAgJGivvPOzs5WZmamvF6vHA6HqqqqFAgElJCQ\noMLCQpWWlqqjo0NtbW0qLi6Wx+PRypUrFQ6HlZSUNOJYPp9PlZWVunTpku666y4tWbLkmp0YAADT\nla3PvMvLy0csp6enWz/X1dWNus+iRYu0Z8+eEY/deeedOnDgwHjHCAAALsMd1gAAMAzxBgDAMMQb\nAADDEG8AAAxDvAEAMAzxBgDAMMQbAADDEG8AAAxDvAEAMAzxBgDAMMQbAADDEG8AAAxDvAEAMAzx\nBgDAMMQbAADDEG8AAAxDvAEAMAzxBgDAMMQbAADDEG8AAAxDvAEAMAzxBgDAMMQbAADDEG8AAAxD\nvAEAMAzxBgDAMMQbAADDEG8AAAxDvAEAMAzxBgDAMMQbAADDEG8AAAxDvAEAMAzxBgDAMDF2Nqqp\nqVFzc7McDod8Pp+ysrKsdUNDQ6qsrFQoFFIgELAer6+v1549exQTE6PS0lItX75cmzdvVktLi+bO\nnStJeuyxx7R8+fKJPSMAAKa5qPFuampSe3u7/H6/Wltb5fP55Pf7rfW1tbXKyMhQKBSyHuvu7tau\nXbt06NAhDQwMaMeOHVakn376aeXl5U38mQAAMENEvWweDAZVUFAgSUpLS1Nvb6/6+/ut9WVlZdb6\ny/fJycmR0+mU2+3W1q1bJ3jYAADMXFHjHYlElJiYaC0nJSUpHA5by06n84p9PvnkEw0ODmrDhg0q\nKipSMBi01u3bt08lJSUqKyvT2bNnv+v4AQCYcWx95n254eFhW9v19PRo586dOnPmjEpKSnTkyBE9\n/PDDmjt3rjIyMvTKK69o586dqqysHPM4LlfCeIeI64jnxx7myR7myT7myp7pOk9R4+12uxWJRKzl\nrq4uuVyuMfdJTk7W4sWLFRMTo9TUVMXHx+vs2bPKycmxtsnPz1d1dXXUAYbD56Jug8nD82MP82QP\n82Qfc2WPifNk5wVH1Mvmubm5amhokCS1tLTI7XaPeqn8ckuXLtWxY8d06dIldXd3a2BgQImJidq4\ncaNOnTolSWpsbNT8+fPtnAcAALhM1Hfe2dnZyszMlNfrlcPhUFVVlQKBgBISElRYWKjS0lJ1dHSo\nra1NxcXF8ng8Wrlype6//355PB5J0pYtWzRr1iw9+uijeuqppzRnzhzFxcVp+/bt1/wEAQCYbmx9\n5l1eXj5iOT093fq5rq5u1H28Xq+8Xu+Ix+655x4dOnRovGMEAACX4Q5rAAAYhngDAGAY4g0AgGGI\nNwAAhiHeAAAYhngDAGAY4g0AgGGINwAAhiHeAAAYhngDAGAY4g0AgGGINwAAhiHeAAAYhngDAGAY\n4g0AgGGINwAAhiHeAAAYhngDAGAY4g0AgGGINwAAhiHeAAAYhngDAGAY4g0AgGGINwAAhiHeAAAY\nhngDAGAY4g0AgGGINwAAhiHeAAAYhngDAGAY4g0AgGGINwAAhiHeAAAYhngDAGAYW/GuqanR2rVr\n5fV6deLEiRHrhoaGVFFRodWrV494vL6+Xg899JBWr16to0ePSpI+/fRTFRcXq6ioSJs2bdIXX3wx\nMWcBAMAMEjXeTU1Nam9vl9/v17Zt27Rt27YR62tra5WRkTHise7ubu3atUsHDhzQ7t279c4770iS\n6urqVFRUpAMHDujWW2/VwYMHJ/BUAACYGaLGOxgMqqCgQJKUlpam3t5e9ff3W+vLysqs9Zfvk5OT\nI6fTKbfbra1bt0qSGhsbdd9990mS8vLyFAwGJ+xEAACYKWKibRCJRJSZmWktJyUlKRwOy+l0SpKc\nTqd6enpG7PPJJ59ocHBQGzZsUF9fnzZu3KicnBydP39esbGxkqTk5GSFw+GoA3S5EsZ1Qri+eH7s\nYZ7sYZ7sY67sma7zFDXe3zQ8PGxru56eHu3cuVNnzpxRSUmJjhw58q2OEw6fG+8QcR3x/NjDPNnD\nPNnHXNlj4jzZecER9bK52+1WJBKxlru6uuRyucbcJzk5WYsXL1ZMTIxSU1MVHx+vs2fPKi4uToOD\ng5Kkzs5Oud3uqAMEAAAjRY13bm6uGhoaJEktLS1yu93WJfOrWbp0qY4dO6ZLly6pu7tbAwMDSkxM\n1JIlS6xjHT58WMuWLZuAUwAAYGaJetk8OztbmZmZ8nq9cjgcqqqqUiAQUEJCggoLC1VaWqqOjg61\ntbWpuLhYHo9HK1eu1P333y+PxyNJ2rJli2bNmqWNGzeqoqJCfr9f8+bN009/+tNrfoIAAEw3tj7z\nLi8vH7Gcnp5u/VxXVzfqPl6vV16vd8Rjbrdbf/rTn8Y7RgAAcBnusAYAgGGINwAAhiHeAAAYhngD\nAGAY4g0AgGGINwAAhiHeAAAYhngDAGAY4g0AgGGINwAAhiHeAAAYhngDAGAY4g0AgGGINwAAhiHe\nAAAYhngDAGAY4g0AgGGINwAAhiHeAAAYhngDAGAY4g0AgGGINwAAhiHeAAAYhngDAGAY4g0AgGGI\nNwAAhiHeAAAYhngDAGAY4g0AgGGINwAAhiHeAAAYhngDAGAY4g0AgGFi7GxUU1Oj5uZmORwO+Xw+\nZWVlWeuGhoZUWVmpUCikQCAgSWpsbNSmTZs0f/58SdKCBQv03HPPafPmzWppadHcuXMlSY899piW\nL18+wacEAMD0FjXeTU1Nam9vl9/vV2trq3w+n/x+v7W+trZWGRkZCoVCI/a7++67VVdXd8Xxnn76\naeXl5U3A0AEAmJmiXjYPBoMqKCiQJKWlpam3t1f9/f3W+rKyMms9AAC49qLGOxKJKDEx0VpOSkpS\nOBy2lp1O56j7ffzxx9qwYYMeeeQRvffee9bj+/btU0lJicrKynT27NnvMnYAAGYkW595X254eDjq\nNrfddpuefPJJPfDAAzp16pRKSkp0+PBhPfzww5o7d64yMjL0yiuvaOfOnaqsrBzzWC5XwniHiOuI\n58ce5ske5sk+5sqe6TpPUePtdrsViUSs5a6uLrlcrjH3SUlJ0YoVKyRJqampuvnmm9XZ2amcnBxr\nm/z8fFVXV0cdYDh8Luo2mDw8P/YwT/YwT/YxV/aYOE92XnBEvWyem5urhoYGSVJLS4vcbvdVL5V/\nrb6+Xnv37pUkhcNhffbZZ0pJSdHGjRt16tQpSV/9i/Sv/zU6AACwL+o77+zsbGVmZsrr9crhcKiq\nqkqBQEAJCQkqLCxUaWmpOjo61NbWpuLiYnk8HuXn56u8vFzvvPOOLly4oOrqasXGxurRRx/VU089\npTlz5iguLk7bt2+/HucIAMC0Yusz7/Ly8hHL6enp1s+jfR1Mknbv3n3FY/fcc48OHTo0nvEBAIBv\n4A5rAAAYhngDAGAY4g0AgGGINwAAhiHeAAAYhngDAGAY4g0AgGGINwAAhiHeAAAYhngDAGAY4g0A\ngGGINwAAhiHeAAAYhngDAGAY4g0AgGGINwAAhiHeAAAYhngDAGAY4g0AgGGINwAAhiHeAAAYhngD\nAGAY4g0AgGGINwAAhiHeAAAYhngDAGAY4g0AgGGINwAAhiHeAAAYhngDAGAY4g0AgGGINwAAhiHe\nAAAYhngDAGCYGDsb1dTUqLm5WQ6HQz6fT1lZWda6oaEhVVZWKhQKKRAISJIaGxu1adMmzZ8/X5K0\nYMECPffcc/r000/17LPP6uLFi3K5XPrtb3+r2NjYa3BaAABMX1Hj3dTUpPb2dvn9frW2tsrn88nv\n91vra2trlZGRoVAoNGK/u+++W3V1dSMeq6urU1FRkR544AH9/ve/18GDB1VUVDRBpwIAwMwQ9bJ5\nMBhUQUGBJCktLU29vb3q7++31peVlVnro2lsbNR9990nScrLy1MwGPw2YwYAYEaLGu9IJKLExERr\nOSkpSeFw2Fp2Op2j7vfxxx9rw4YNeuSRR/Tee+9Jks6fP29dJk9OTh5xHAAAYI+tz7wvNzw8HHWb\n2267TU8++aQeeOABnTp1SiUlJTp8+PC4jyNJLlfCeIc4qf7n/z882UMwAvNkH3NlD/NkH3Nlvqjv\nvN1utyKRiLXc1dUll8s15j4pKSlasWKFHA6HUlNTdfPNN6uzs1NxcXEaHByUJHV2dsrtdn/H4QMA\nMPNEjXdubq4aGhokSS0tLXK73Ve9VP61+vp67d27V5IUDof12WefKSUlRUuWLLGOdfjwYS1btuy7\njh8AgBnHMWzj+vXvfvc7HT9+XA6HQ1VVVfr3v/+thIQEFRYWqrS0VB0dHQqFQlq0aJE8Ho/y8vJU\nXl6uvr4+XbhwQU8++aTuvfdedXV1qaKiQkNDQ5o3b562b9+uG2+88XqcJwAA04ateAMAgKmDO6wB\nAGAY4g0AgGGmbLxramq0du1aeb1enThxYrKHM6V99NFHKigo0L59+yZ7KFNabW2t1q5dq5/97GdX\nfHURXzl//rw2bdqkdevWac2aNTpy5MhkD2lKGxwcVEFBgXVraFypsbFR99xzj4qLi1VcXKytW7dO\n9pCmtPr6ej300ENavXq1jh49etXtxv097+sh2i1Z8V8DAwPaunWrcnJyJnsoU9qxY8cUCoXk9/vV\n3d2tVatW6Sc/+clkD2vKOXLkiBYtWqRf/vKXOn36tH7xi18oLy9vsoc1Zb300kv63ve+N9nDmPJG\nu102rtTd3a1du3bp0KFDGhgY0I4dO7R8+fJRt52S8b7aLVmjfUVtJoqNjdWrr76qV199dbKHMqX9\n6Ec/sn6hzk033aTz58/r4sWLuuGGGyZ5ZFPLihUrrJ8//fRTpaSkTOJoprbW1lZ9/PHHV/2fKzBe\nwWBQOTk5cjqdcjqdY16lmJKXzaPdkhX/FRMTo9mzZ0/2MKa8G264QXFxcZKkgwcP6sc//jHhHoPX\n61V5ebl8Pt9kD2XKeuGFF7R58+bJHoYRRrtdNq70ySefaHBwUBs2bFBRUdGYv/9jSr7z/ia+zYaJ\n8s9//lMHDx7UH//4x8keypT22muv6T//+Y9+9atfqb6+Xg6HY7KHNKX87W9/0w9/+EP94Ac/mOyh\nTHlXu102vw56dD09Pdq5c6fOnDmjkpISHTlyZNS/f1My3t/mlqxANP/617+0e/du7dmzRwkJZt0z\n/3o5efKkkpOTdcsttygjI0MXL17U2bNnlZycPNlDm1KOHj2qU6dO6ejRo+ro6FBsbKy+//3va8mS\nJZM9tCnn69tlSxpxu2xe+FwpOTlZixcvVkxMjFJTUxUfH3/Vv39T8rL5t7klKzCWc+fOqba2Vi+/\n/LLmzp072cOZso4fP25dlYhEIhoYGBjxERa+8oc//EGHDh3SX//6V61Zs0aPP/444b6Kq90uG1da\nunSpjh07pkuXLqm7u3vMv39T8p13dna2MjMz5fV6rVuyYnQnT57UCy+8oNOnTysmJkYNDQ3asWMH\ngfqGt956S93d3Xrqqaesx1544QXNmzdvEkc19Xi9Xv36179WUVGRBgcHVVlZqVmzpuRrfBgiPz9f\n5eXleuedd3ThwgVVV1dzyfwqUlJSdP/998vj8UiStmzZctW/f9weFQAAw/CSGgAAwxBvAAAMQ7wB\nADAM8QYAwDDEGwAAwxBvAAAMQ7wBADAM8QYAwDD/BxrczT5G+ZijAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fae955d6710>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard Deviation Error at each fold : [0.23908619784504503, 0.2392757614134787, 0.24077840434723377, 0.23958764575829025, 0.2410957486145287]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAecAAAFKCAYAAAAnj5dkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fae92c3df98>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x=np.arange(1,numberOfFolds+1,1)\n",
    "print(\"Error at each fold :\",errorTracker[minErrorIndex])\n",
    "plt.bar(x,errorTracker[minErrorIndex])\n",
    "plt.xlim(0,6)\n",
    "plt.ylim(0.15,0.185)\n",
    "plt.show()\n",
    "print(\"Standard Deviation Error at each fold :\",stdTracker[minErrorIndex])\n",
    "\n",
    "plt.bar(x,stdTracker[minErrorIndex])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AN0aYof-Cdwn"
   },
   "source": [
    "** K Nearest Neighbour:**\n",
    "\n",
    "This is a classifier that does not require any training.\n",
    " The prediction is done by calculating the eucledian distance. The 1 nearest neighbour that is closest is considered to be the class of the data point.\n",
    " \n",
    " Eucledian Distance is claculated as $\\sqrt{(x1-x2)^2+(y1-y2)^2}$\n",
    " \n",
    " \n",
    " This is the simplest model that can be iplemented, but the drawback is the time taken to claculate. It has to find the distance between the given point and all the training set and then sort these distances to find the minimum. \n",
    " \n",
    "\n",
    " \n",
    " \n",
    " **Accuracy for 1000 images:**  96.91%\n",
    " \n",
    "**Observation:**\n",
    "\n",
    "1. The accuracy of 1 NN Classifierr is very higher  than MLFFNN Classifier\n",
    "2. 1 NN classification is kind of unsupervised learning.\n",
    "3. Even though the accuracy is high, the performance is very poor. Time complexity is very high as it involves finding distance for each and every point and then sorting it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 208
    },
    "colab_type": "code",
    "id": "AofS44zF6gWH",
    "outputId": "4933d0f6-c967-4e34-ec97-e98d0c14b40a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage Completed : 0.0\n",
      "Percentage Completed : 10.0\n",
      "Percentage Completed : 20.0\n",
      "Percentage Completed : 30.0\n",
      "Percentage Completed : 40.0\n",
      "Percentage Completed : 50.0\n",
      "Percentage Completed : 60.0\n",
      "Percentage Completed : 70.0\n",
      "Percentage Completed : 80.0\n",
      "Percentage Completed : 90.0\n",
      "Accuracy for 10000 test images in percentage:  96.91\n"
     ]
    }
   ],
   "source": [
    "train_imgs=train_imgs.reshape(nImg,nR,nC)\n",
    "test_imgs=test_imgs.reshape(nImgTest,nRTest,nCTest)\n",
    "\n",
    "def getAccuracy(predictions, answers):\n",
    "    correct=0\n",
    "    for i in range(len(answers)):\n",
    "      if predictions[i]==answers[i][0]:\n",
    "        correct+=1\n",
    "    total = float(len(answers))\n",
    "    return correct / total\n",
    "\n",
    "def predictTestData(predictor, test_set):\n",
    "   \n",
    "    predictions=[]\n",
    "    for i in range(len(test_set)):\n",
    "      predictions.append(predictor.predict(test_set[i, :, :]) )\n",
    "      if i%1000==0:\n",
    "        print(\"Percentage Completed : \",end=\"\")\n",
    "        print((i/len(test_set))*100)\n",
    "    return predictions\n",
    "\n",
    "\n",
    "class NearestNeighbor(object):\n",
    "    \n",
    "    def __init__(self, dataset, k):\n",
    "        self.dataset = dataset\n",
    "        self.k = k\n",
    "        \n",
    "    def predict(self, point):\n",
    "      candidates = self.dataset[:]\n",
    "      neighbors = []\n",
    "      while len(neighbors) < self.k:\n",
    "          distances = [self.eucledianDistance(x[0], point) for x in candidates]\n",
    "          best_distance = min(distances)\n",
    "          index = distances.index(best_distance)\n",
    "          neighbors.append(candidates[index])\n",
    "          del candidates[index]\n",
    "\n",
    "      prediction = [value[1][0] for value in neighbors]\n",
    "      return prediction\n",
    "      \n",
    "    def eucledianDistance(self, img1, img2):\n",
    "          return np.sum((img1-img2)**2)\n",
    "\n",
    "    \n",
    "   \n",
    "           \n",
    "dataset = []\n",
    "for i in range(len(train_imgs)):\n",
    "    dataset.append((train_imgs[i, :, :], train_labels[i]))\n",
    "    \n",
    "predictor= NearestNeighbor(dataset, 1)\n",
    "\n",
    "test_set = test_imgs[:, :, :]\n",
    "prediction = predictTestData(predictor, test_set) \n",
    "\n",
    "labels = np.asarray(test_labels[:])\n",
    "accuracy = getAccuracy(prediction, labels)\n",
    "print(\"Accuracy for 10000 test images in percentage: \",accuracy*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VIGpZByLILKi"
   },
   "source": [
    "## **Weight Decay:**\n",
    "It is a regularization term that is genaerally used to reduce the change that is caused due to big weights.\n",
    "It is mainly used to avoid overfitting.\n",
    "It is observed that for the best model used in the 1st question the accuracy using Weight Decay reguarizaton variation is pretty high.\n",
    "\n",
    "\n",
    "**Accuracy: ** 93.24%\n",
    "\n",
    "**Error: **6.76%\n",
    "\n",
    "**Observations:**\n",
    "\n",
    "1.  The accuracy attained is slightly high when compared to normal back propagation\n",
    "\n",
    "2.  The lambda value used is 0.0001. If higher or lower values is used then the accuracy attained is not as high as 93.24%. It is around 90%.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "colab_type": "code",
    "id": "GXGeKRNEiQcd",
    "outputId": "15af853b-33bb-49d8-c13c-7410b1facef4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 955    0   12    3    4    8   17    1    9   13]\n",
      " [   0 1114   11    2    0    1    4   17    4    3]\n",
      " [   3    2  923    9    1    2    2   23    4    1]\n",
      " [   3    3   29  944    0   19    3   10   18    7]\n",
      " [   1    0   19    1  927    7    4    9    5   28]\n",
      " [   6    1    0   22    0  825   15    1   21    5]\n",
      " [   7    5   14    4   15   12  906    0   10    1]\n",
      " [   0    1    9    6    2    0    0  915    5    9]\n",
      " [   3    9   10   13    4   10    5    0  881    8]\n",
      " [   2    0    5    6   29    8    2   52   17  934]]\n",
      "digit:  0 Precision:  0.974 Recall:  0.934 Accuracy:  0.991 Specificity:  0.997 errorRate:  0.009\n",
      "digit:  1 Precision:  0.981 Recall:  0.964 Accuracy:  0.994 Specificity:  0.998 errorRate:  0.006\n",
      "digit:  2 Precision:  0.894 Recall:  0.952 Accuracy:  0.984 Specificity:  0.988 errorRate:  0.016\n",
      "digit:  3 Precision:  0.935 Recall:  0.911 Accuracy:  0.984 Specificity:  0.993 errorRate:  0.016\n",
      "digit:  4 Precision:  0.944 Recall:  0.926 Accuracy:  0.987 Specificity:  0.994 errorRate:  0.013\n",
      "digit:  5 Precision:  0.925 Recall:  0.921 Accuracy:  0.986 Specificity:  0.993 errorRate:  0.014\n",
      "digit:  6 Precision:  0.946 Recall:  0.93 Accuracy:  0.988 Specificity:  0.994 errorRate:  0.012\n",
      "digit:  7 Precision:  0.89 Recall:  0.966 Accuracy:  0.986 Specificity:  0.988 errorRate:  0.014\n",
      "digit:  8 Precision:  0.905 Recall:  0.934 Accuracy:  0.984 Specificity:  0.99 errorRate:  0.016\n",
      "digit:  9 Precision:  0.926 Recall:  0.885 Accuracy:  0.98 Specificity:  0.992 errorRate:  0.02\n",
      "Accuracy :  0.9324 Total Error :  0.0676 Average error:  0.013600000000000001 Average Standar Deviation of Error Rate: 0.0037469987990390394\n"
     ]
    }
   ],
   "source": [
    "nn = NeuralNetwork(inNodes = image_pixels, outNodes = 10,  hiddenNodes = hyperParameters[minErrorIndex][0], learningRate = hyperParameters[minErrorIndex][1],epochs=hyperParameters[minErrorIndex][2])   \n",
    "\n",
    "for i in range(train_imgs.shape[0]):\n",
    "  nn.train(train_imgs[i],train_labels_one_hot[i],\"Weight Decay\")\n",
    "cm=nn.confusion_matrix(test_imgs, test_labels)\n",
    "print(cm)\n",
    "conMatrixMeasures=measuresOfConMatrix(cm)\n",
    "corrects, wrongs = nn.evaluate(test_imgs, test_labels)\n",
    "accuracy=corrects / ( corrects + wrongs)\n",
    "for i in range(10):\n",
    "  print(\"digit: \", i, \"Precision: \", conMatrixMeasures.precision()[i], \"Recall: \", conMatrixMeasures.recall()[i],\n",
    "       \"Accuracy: \", conMatrixMeasures.accuracy()[i], \"Specificity: \", conMatrixMeasures.specificity()[i],\n",
    "       \"errorRate: \",conMatrixMeasures.errorRate()[i])\n",
    "print(\"Accuracy : \",accuracy,\"Total Error : \",1-accuracy,\"Average error: \",np.average(conMatrixMeasures.errorRate()),\"Average Standar Deviation of Error Rate:\",np.std(conMatrixMeasures.errorRate()));\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zMA2je8XZbrA"
   },
   "source": [
    "## **Deskewing:**\n",
    "It will generally rotatte the image from slant to straight. In the below code scipy's interpolation is used inorder to deskew the image.\n",
    "\n",
    "**Observation:**\n",
    "\n",
    "1) The variation in  the result is not much different from mthe 1st question.\n",
    "\n",
    "2) Accuracy acttained: 92.47%\n",
    "\n",
    "3) Error: 7.53%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "colab_type": "code",
    "id": "X_uYn1is8HLv",
    "outputId": "18d077bd-5db7-4739-c632-cc99b0ff27ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 959    0   15    4    1   17   11    3    7    7]\n",
      " [   0 1112    6    2    0    3    3   17    2    4]\n",
      " [   2    1  906    7    4    1    2   17    5    0]\n",
      " [   1    6   28  944    1   45    2   11   32   11]\n",
      " [   3    0   14    0  916   12   14   10   15   30]\n",
      " [   1    0    0   10    0  760    9    0    7    0]\n",
      " [   2    4   11    1   10   15  912    0    9    0]\n",
      " [   5    0   10    9    0    3    0  923    8    4]\n",
      " [   6   11   33   22    3   22    4    8  876   14]\n",
      " [   1    1    9   11   47   14    1   39   13  939]]\n",
      "digit:  0 Precision:  0.979 Recall:  0.937 Accuracy:  0.991 Specificity:  0.998 errorRate:  0.009\n",
      "digit:  1 Precision:  0.98 Recall:  0.968 Accuracy:  0.994 Specificity:  0.997 errorRate:  0.006\n",
      "digit:  2 Precision:  0.878 Recall:  0.959 Accuracy:  0.984 Specificity:  0.986 errorRate:  0.016\n",
      "digit:  3 Precision:  0.935 Recall:  0.873 Accuracy:  0.98 Specificity:  0.993 errorRate:  0.02\n",
      "digit:  4 Precision:  0.933 Recall:  0.903 Accuracy:  0.984 Specificity:  0.993 errorRate:  0.016\n",
      "digit:  5 Precision:  0.852 Recall:  0.966 Accuracy:  0.984 Specificity:  0.986 errorRate:  0.016\n",
      "digit:  6 Precision:  0.952 Recall:  0.946 Accuracy:  0.99 Specificity:  0.995 errorRate:  0.01\n",
      "digit:  7 Precision:  0.898 Recall:  0.959 Accuracy:  0.986 Specificity:  0.988 errorRate:  0.014\n",
      "digit:  8 Precision:  0.899 Recall:  0.877 Accuracy:  0.978 Specificity:  0.989 errorRate:  0.022\n",
      "digit:  9 Precision:  0.931 Recall:  0.873 Accuracy:  0.979 Specificity:  0.992 errorRate:  0.021\n",
      "Accuracy :  0.9247 Total Error :  0.07530000000000003 Average error:  0.015 Average Standar Deviation of Error Rate: 0.005059644256269408\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def moments(image):\n",
    "    c0,c1 = np.mgrid[:image.shape[0],:image.shape[1]] # A trick in numPy to create a mesh grid\n",
    "    totalImage = np.sum(image) #sum of pixels\n",
    "    m0 = np.sum(c0*image)/totalImage #mu_x\n",
    "    m1 = np.sum(c1*image)/totalImage #mu_y\n",
    "    m00 = np.sum((c0-m0)**2*image)/totalImage #var(x)\n",
    "    m11 = np.sum((c1-m1)**2*image)/totalImage #var(y)\n",
    "    m01 = np.sum((c0-m0)*(c1-m1)*image)/totalImage #covariance(x,y)\n",
    "    mu_vector = np.array([m0,m1]) # Notice that these are \\mu_x, \\mu_y respectively\n",
    "    covariance_matrix = np.array([[m00,m01],[m01,m11]]) # Do you see a similarity between the covariance matrix\n",
    "    return mu_vector, covariance_matrix\n",
    "  \n",
    "def deskew(image):\n",
    "    c,v = moments(image)\n",
    "    alpha = v[0,1]/v[0,0]\n",
    "    affine = np.array([[1,0],[alpha,1]])\n",
    "    ocenter = np.array(image.shape)/2.0\n",
    "    offset = c-np.dot(affine,ocenter)\n",
    "    return interpolation.affine_transform(image,affine,offset=offset)\n",
    "\n",
    "  \n",
    "def getNormalizedDeskewedImg(img):\n",
    "  normalizedDeskwedImg=(0.99 - (((0.98) * (255 - deskew(img.reshape(28,28)))) / 255)).reshape(28*28)\n",
    "  return normalizedDeskwedImg\n",
    "  \n",
    "nn = NeuralNetwork(inNodes = image_pixels, outNodes = 10,  hiddenNodes = hyperParameters[minErrorIndex][0], learningRate = hyperParameters[minErrorIndex][1],epochs=hyperParameters[minErrorIndex][2])   \n",
    "\n",
    "for i in range(train_imgs.shape[0]):\n",
    "  nn.train(train_imgs[i],train_labels_one_hot[i],None)\n",
    "cm=nn.confusion_matrix(test_imgs, test_labels)\n",
    "print(cm)\n",
    "conMatrixMeasures=measuresOfConMatrix(cm)\n",
    "corrects, wrongs = nn.evaluate(test_imgs, test_labels)\n",
    "accuracy=corrects / ( corrects + wrongs)\n",
    "for i in range(10):\n",
    "  print(\"digit: \", i, \"Precision: \", conMatrixMeasures.precision()[i], \"Recall: \", conMatrixMeasures.recall()[i],\n",
    "       \"Accuracy: \", conMatrixMeasures.accuracy()[i], \"Specificity: \", conMatrixMeasures.specificity()[i],\n",
    "       \"errorRate: \",conMatrixMeasures.errorRate()[i])\n",
    "print(\"Accuracy : \",accuracy,\"Total Error : \",1-accuracy,\"Average error: \",np.average(conMatrixMeasures.errorRate()),\"Average Standar Deviation of Error Rate:\",np.std(conMatrixMeasures.errorRate()));\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "d9NKg_tdb8NC"
   },
   "source": [
    "## Actual Image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 364
    },
    "colab_type": "code",
    "id": "lM3gOMZP5cZC",
    "outputId": "5adb6721-af0c-4505-85cb-4cc47a141cd3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f5607a2e400>"
      ]
     },
     "execution_count": 28,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUsAAAFKCAYAAACU6307AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYZ0Aw5r6AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f5607dc26d8>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(train_imgs[1].reshape(28,28))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WM3_oF0ub2qO"
   },
   "source": [
    "## Deskewed Image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 364
    },
    "colab_type": "code",
    "id": "pqxMLqdo5pNp",
    "outputId": "e9339f59-2659-4efb-f97f-d0fa198d81f4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f5607999f28>"
      ]
     },
     "execution_count": 30,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUsAAAFKCAYAAACU6307AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f5607bc6208>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(deskew(train_imgs[1].reshape(28,28)))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "name": "NN Assignment 2.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
