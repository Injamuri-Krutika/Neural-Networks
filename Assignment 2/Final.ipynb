{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "tHy46ogZcrQe",
    "outputId": "32b76fd2-7439-434c-dcb2-8542de582c20"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 53692\n",
      "drwxr-xr-x 1 root root     4096 Oct  1 06:46 .\n",
      "drwxr-xr-x 1 root root     4096 Oct  1 06:24 ..\n",
      "drwxr-xr-x 4 root root     4096 Sep 27 20:11 .config\n",
      "drwxr-xr-x 2 root root     4096 Sep 27 20:32 sample_data\n",
      "-rw-r--r-- 1 root root  7840016 Oct  1 06:49 t10k-images-idx3-ubyte\n",
      "-rw-r--r-- 1 root root    10008 Oct  1 06:46 t10k-labels-idx1-ubyte\n",
      "-rw-r--r-- 1 root root 47040016 Oct  1 06:46 train-images-idx3-ubyte\n",
      "-rw-r--r-- 1 root root    60008 Oct  1 06:31 train-labels-idx1-ubyte\n"
     ]
    }
   ],
   "source": [
    "!ls -al\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 46,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "Ly8gQ29weXJpZ2h0IDIwMTcgR29vZ2xlIExMQwovLwovLyBMaWNlbnNlZCB1bmRlciB0aGUgQXBhY2hlIExpY2Vuc2UsIFZlcnNpb24gMi4wICh0aGUgIkxpY2Vuc2UiKTsKLy8geW91IG1heSBub3QgdXNlIHRoaXMgZmlsZSBleGNlcHQgaW4gY29tcGxpYW5jZSB3aXRoIHRoZSBMaWNlbnNlLgovLyBZb3UgbWF5IG9idGFpbiBhIGNvcHkgb2YgdGhlIExpY2Vuc2UgYXQKLy8KLy8gICAgICBodHRwOi8vd3d3LmFwYWNoZS5vcmcvbGljZW5zZXMvTElDRU5TRS0yLjAKLy8KLy8gVW5sZXNzIHJlcXVpcmVkIGJ5IGFwcGxpY2FibGUgbGF3IG9yIGFncmVlZCB0byBpbiB3cml0aW5nLCBzb2Z0d2FyZQovLyBkaXN0cmlidXRlZCB1bmRlciB0aGUgTGljZW5zZSBpcyBkaXN0cmlidXRlZCBvbiBhbiAiQVMgSVMiIEJBU0lTLAovLyBXSVRIT1VUIFdBUlJBTlRJRVMgT1IgQ09ORElUSU9OUyBPRiBBTlkgS0lORCwgZWl0aGVyIGV4cHJlc3Mgb3IgaW1wbGllZC4KLy8gU2VlIHRoZSBMaWNlbnNlIGZvciB0aGUgc3BlY2lmaWMgbGFuZ3VhZ2UgZ292ZXJuaW5nIHBlcm1pc3Npb25zIGFuZAovLyBsaW1pdGF0aW9ucyB1bmRlciB0aGUgTGljZW5zZS4KCi8qKgogKiBAZmlsZW92ZXJ2aWV3IEhlbHBlcnMgZm9yIGdvb2dsZS5jb2xhYiBQeXRob24gbW9kdWxlLgogKi8KKGZ1bmN0aW9uKHNjb3BlKSB7CmZ1bmN0aW9uIHNwYW4odGV4dCwgc3R5bGVBdHRyaWJ1dGVzID0ge30pIHsKICBjb25zdCBlbGVtZW50ID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnc3BhbicpOwogIGVsZW1lbnQudGV4dENvbnRlbnQgPSB0ZXh0OwogIGZvciAoY29uc3Qga2V5IG9mIE9iamVjdC5rZXlzKHN0eWxlQXR0cmlidXRlcykpIHsKICAgIGVsZW1lbnQuc3R5bGVba2V5XSA9IHN0eWxlQXR0cmlidXRlc1trZXldOwogIH0KICByZXR1cm4gZWxlbWVudDsKfQoKLy8gTWF4IG51bWJlciBvZiBieXRlcyB3aGljaCB3aWxsIGJlIHVwbG9hZGVkIGF0IGEgdGltZS4KY29uc3QgTUFYX1BBWUxPQURfU0laRSA9IDEwMCAqIDEwMjQ7Ci8vIE1heCBhbW91bnQgb2YgdGltZSB0byBibG9jayB3YWl0aW5nIGZvciB0aGUgdXNlci4KY29uc3QgRklMRV9DSEFOR0VfVElNRU9VVF9NUyA9IDMwICogMTAwMDsKCmZ1bmN0aW9uIF91cGxvYWRGaWxlcyhpbnB1dElkLCBvdXRwdXRJZCkgewogIGNvbnN0IHN0ZXBzID0gdXBsb2FkRmlsZXNTdGVwKGlucHV0SWQsIG91dHB1dElkKTsKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIC8vIENhY2hlIHN0ZXBzIG9uIHRoZSBvdXRwdXRFbGVtZW50IHRvIG1ha2UgaXQgYXZhaWxhYmxlIGZvciB0aGUgbmV4dCBjYWxsCiAgLy8gdG8gdXBsb2FkRmlsZXNDb250aW51ZSBmcm9tIFB5dGhvbi4KICBvdXRwdXRFbGVtZW50LnN0ZXBzID0gc3RlcHM7CgogIHJldHVybiBfdXBsb2FkRmlsZXNDb250aW51ZShvdXRwdXRJZCk7Cn0KCi8vIFRoaXMgaXMgcm91Z2hseSBhbiBhc3luYyBnZW5lcmF0b3IgKG5vdCBzdXBwb3J0ZWQgaW4gdGhlIGJyb3dzZXIgeWV0KSwKLy8gd2hlcmUgdGhlcmUgYXJlIG11bHRpcGxlIGFzeW5jaHJvbm91cyBzdGVwcyBhbmQgdGhlIFB5dGhvbiBzaWRlIGlzIGdvaW5nCi8vIHRvIHBvbGwgZm9yIGNvbXBsZXRpb24gb2YgZWFjaCBzdGVwLgovLyBUaGlzIHVzZXMgYSBQcm9taXNlIHRvIGJsb2NrIHRoZSBweXRob24gc2lkZSBvbiBjb21wbGV0aW9uIG9mIGVhY2ggc3RlcCwKLy8gdGhlbiBwYXNzZXMgdGhlIHJlc3VsdCBvZiB0aGUgcHJldmlvdXMgc3RlcCBhcyB0aGUgaW5wdXQgdG8gdGhlIG5leHQgc3RlcC4KZnVuY3Rpb24gX3VwbG9hZEZpbGVzQ29udGludWUob3V0cHV0SWQpIHsKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIGNvbnN0IHN0ZXBzID0gb3V0cHV0RWxlbWVudC5zdGVwczsKCiAgY29uc3QgbmV4dCA9IHN0ZXBzLm5leHQob3V0cHV0RWxlbWVudC5sYXN0UHJvbWlzZVZhbHVlKTsKICByZXR1cm4gUHJvbWlzZS5yZXNvbHZlKG5leHQudmFsdWUucHJvbWlzZSkudGhlbigodmFsdWUpID0+IHsKICAgIC8vIENhY2hlIHRoZSBsYXN0IHByb21pc2UgdmFsdWUgdG8gbWFrZSBpdCBhdmFpbGFibGUgdG8gdGhlIG5leHQKICAgIC8vIHN0ZXAgb2YgdGhlIGdlbmVyYXRvci4KICAgIG91dHB1dEVsZW1lbnQubGFzdFByb21pc2VWYWx1ZSA9IHZhbHVlOwogICAgcmV0dXJuIG5leHQudmFsdWUucmVzcG9uc2U7CiAgfSk7Cn0KCi8qKgogKiBHZW5lcmF0b3IgZnVuY3Rpb24gd2hpY2ggaXMgY2FsbGVkIGJldHdlZW4gZWFjaCBhc3luYyBzdGVwIG9mIHRoZSB1cGxvYWQKICogcHJvY2Vzcy4KICogQHBhcmFtIHtzdHJpbmd9IGlucHV0SWQgRWxlbWVudCBJRCBvZiB0aGUgaW5wdXQgZmlsZSBwaWNrZXIgZWxlbWVudC4KICogQHBhcmFtIHtzdHJpbmd9IG91dHB1dElkIEVsZW1lbnQgSUQgb2YgdGhlIG91dHB1dCBkaXNwbGF5LgogKiBAcmV0dXJuIHshSXRlcmFibGU8IU9iamVjdD59IEl0ZXJhYmxlIG9mIG5leHQgc3RlcHMuCiAqLwpmdW5jdGlvbiogdXBsb2FkRmlsZXNTdGVwKGlucHV0SWQsIG91dHB1dElkKSB7CiAgY29uc3QgaW5wdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQoaW5wdXRJZCk7CiAgaW5wdXRFbGVtZW50LmRpc2FibGVkID0gZmFsc2U7CgogIGNvbnN0IG91dHB1dEVsZW1lbnQgPSBkb2N1bWVudC5nZXRFbGVtZW50QnlJZChvdXRwdXRJZCk7CiAgb3V0cHV0RWxlbWVudC5pbm5lckhUTUwgPSAnJzsKCiAgY29uc3QgcGlja2VkUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICBpbnB1dEVsZW1lbnQuYWRkRXZlbnRMaXN0ZW5lcignY2hhbmdlJywgKGUpID0+IHsKICAgICAgcmVzb2x2ZShlLnRhcmdldC5maWxlcyk7CiAgICB9KTsKICB9KTsKCiAgY29uc3QgY2FuY2VsID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnYnV0dG9uJyk7CiAgaW5wdXRFbGVtZW50LnBhcmVudEVsZW1lbnQuYXBwZW5kQ2hpbGQoY2FuY2VsKTsKICBjYW5jZWwudGV4dENvbnRlbnQgPSAnQ2FuY2VsIHVwbG9hZCc7CiAgY29uc3QgY2FuY2VsUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICBjYW5jZWwub25jbGljayA9ICgpID0+IHsKICAgICAgcmVzb2x2ZShudWxsKTsKICAgIH07CiAgfSk7CgogIC8vIENhbmNlbCB1cGxvYWQgaWYgdXNlciBoYXNuJ3QgcGlja2VkIGFueXRoaW5nIGluIHRpbWVvdXQuCiAgY29uc3QgdGltZW91dFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgc2V0VGltZW91dCgoKSA9PiB7CiAgICAgIHJlc29sdmUobnVsbCk7CiAgICB9LCBGSUxFX0NIQU5HRV9USU1FT1VUX01TKTsKICB9KTsKCiAgLy8gV2FpdCBmb3IgdGhlIHVzZXIgdG8gcGljayB0aGUgZmlsZXMuCiAgY29uc3QgZmlsZXMgPSB5aWVsZCB7CiAgICBwcm9taXNlOiBQcm9taXNlLnJhY2UoW3BpY2tlZFByb21pc2UsIHRpbWVvdXRQcm9taXNlLCBjYW5jZWxQcm9taXNlXSksCiAgICByZXNwb25zZTogewogICAgICBhY3Rpb246ICdzdGFydGluZycsCiAgICB9CiAgfTsKCiAgaWYgKCFmaWxlcykgewogICAgcmV0dXJuIHsKICAgICAgcmVzcG9uc2U6IHsKICAgICAgICBhY3Rpb246ICdjb21wbGV0ZScsCiAgICAgIH0KICAgIH07CiAgfQoKICBjYW5jZWwucmVtb3ZlKCk7CgogIC8vIERpc2FibGUgdGhlIGlucHV0IGVsZW1lbnQgc2luY2UgZnVydGhlciBwaWNrcyBhcmUgbm90IGFsbG93ZWQuCiAgaW5wdXRFbGVtZW50LmRpc2FibGVkID0gdHJ1ZTsKCiAgZm9yIChjb25zdCBmaWxlIG9mIGZpbGVzKSB7CiAgICBjb25zdCBsaSA9IGRvY3VtZW50LmNyZWF0ZUVsZW1lbnQoJ2xpJyk7CiAgICBsaS5hcHBlbmQoc3BhbihmaWxlLm5hbWUsIHtmb250V2VpZ2h0OiAnYm9sZCd9KSk7CiAgICBsaS5hcHBlbmQoc3BhbigKICAgICAgICBgKCR7ZmlsZS50eXBlIHx8ICduL2EnfSkgLSAke2ZpbGUuc2l6ZX0gYnl0ZXMsIGAgKwogICAgICAgIGBsYXN0IG1vZGlmaWVkOiAkewogICAgICAgICAgICBmaWxlLmxhc3RNb2RpZmllZERhdGUgPyBmaWxlLmxhc3RNb2RpZmllZERhdGUudG9Mb2NhbGVEYXRlU3RyaW5nKCkgOgogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAnbi9hJ30gLSBgKSk7CiAgICBjb25zdCBwZXJjZW50ID0gc3BhbignMCUgZG9uZScpOwogICAgbGkuYXBwZW5kQ2hpbGQocGVyY2VudCk7CgogICAgb3V0cHV0RWxlbWVudC5hcHBlbmRDaGlsZChsaSk7CgogICAgY29uc3QgZmlsZURhdGFQcm9taXNlID0gbmV3IFByb21pc2UoKHJlc29sdmUpID0+IHsKICAgICAgY29uc3QgcmVhZGVyID0gbmV3IEZpbGVSZWFkZXIoKTsKICAgICAgcmVhZGVyLm9ubG9hZCA9IChlKSA9PiB7CiAgICAgICAgcmVzb2x2ZShlLnRhcmdldC5yZXN1bHQpOwogICAgICB9OwogICAgICByZWFkZXIucmVhZEFzQXJyYXlCdWZmZXIoZmlsZSk7CiAgICB9KTsKICAgIC8vIFdhaXQgZm9yIHRoZSBkYXRhIHRvIGJlIHJlYWR5LgogICAgbGV0IGZpbGVEYXRhID0geWllbGQgewogICAgICBwcm9taXNlOiBmaWxlRGF0YVByb21pc2UsCiAgICAgIHJlc3BvbnNlOiB7CiAgICAgICAgYWN0aW9uOiAnY29udGludWUnLAogICAgICB9CiAgICB9OwoKICAgIC8vIFVzZSBhIGNodW5rZWQgc2VuZGluZyB0byBhdm9pZCBtZXNzYWdlIHNpemUgbGltaXRzLiBTZWUgYi82MjExNTY2MC4KICAgIGxldCBwb3NpdGlvbiA9IDA7CiAgICB3aGlsZSAocG9zaXRpb24gPCBmaWxlRGF0YS5ieXRlTGVuZ3RoKSB7CiAgICAgIGNvbnN0IGxlbmd0aCA9IE1hdGgubWluKGZpbGVEYXRhLmJ5dGVMZW5ndGggLSBwb3NpdGlvbiwgTUFYX1BBWUxPQURfU0laRSk7CiAgICAgIGNvbnN0IGNodW5rID0gbmV3IFVpbnQ4QXJyYXkoZmlsZURhdGEsIHBvc2l0aW9uLCBsZW5ndGgpOwogICAgICBwb3NpdGlvbiArPSBsZW5ndGg7CgogICAgICBjb25zdCBiYXNlNjQgPSBidG9hKFN0cmluZy5mcm9tQ2hhckNvZGUuYXBwbHkobnVsbCwgY2h1bmspKTsKICAgICAgeWllbGQgewogICAgICAgIHJlc3BvbnNlOiB7CiAgICAgICAgICBhY3Rpb246ICdhcHBlbmQnLAogICAgICAgICAgZmlsZTogZmlsZS5uYW1lLAogICAgICAgICAgZGF0YTogYmFzZTY0LAogICAgICAgIH0sCiAgICAgIH07CiAgICAgIHBlcmNlbnQudGV4dENvbnRlbnQgPQogICAgICAgICAgYCR7TWF0aC5yb3VuZCgocG9zaXRpb24gLyBmaWxlRGF0YS5ieXRlTGVuZ3RoKSAqIDEwMCl9JSBkb25lYDsKICAgIH0KICB9CgogIC8vIEFsbCBkb25lLgogIHlpZWxkIHsKICAgIHJlc3BvbnNlOiB7CiAgICAgIGFjdGlvbjogJ2NvbXBsZXRlJywKICAgIH0KICB9Owp9CgpzY29wZS5nb29nbGUgPSBzY29wZS5nb29nbGUgfHwge307CnNjb3BlLmdvb2dsZS5jb2xhYiA9IHNjb3BlLmdvb2dsZS5jb2xhYiB8fCB7fTsKc2NvcGUuZ29vZ2xlLmNvbGFiLl9maWxlcyA9IHsKICBfdXBsb2FkRmlsZXMsCiAgX3VwbG9hZEZpbGVzQ29udGludWUsCn07Cn0pKHNlbGYpOwo=",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": "OK"
      }
     }
    },
    "colab_type": "code",
    "id": "_P7_wwx9YAt5",
    "outputId": "a1e9d87b-b739-41d3-961a-2a1615ccf3ba"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-5c6c0364-072a-4f60-aaad-9520e2230b84\" name=\"files[]\" multiple disabled />\n",
       "     <output id=\"result-5c6c0364-072a-4f60-aaad-9520e2230b84\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from google.colab import files\n",
    "import io\n",
    "from google.colab import files\n",
    "uploaded = files.upload()\n",
    "\n",
    "for fn in uploaded.keys():\n",
    "  print('User uploaded file \"{name}\" with length {length} bytes'.format(name=fn, length=len(uploaded[fn])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cWwywd-DZtkC"
   },
   "source": [
    "**Imports Used throughout assignment:**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wkcrilnxZsAR"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import struct as st\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "531BuTd_TtU_",
    "outputId": "29c54384-ccde-48b7-fef0-664f81c9cf4b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0, 8, 3)\n",
      "Data is  3 -D\n",
      "no. of images ::  60000\n",
      "no. of rows ::  28\n",
      "no. of columns ::  28\n",
      "no. of images test ::  10000\n",
      "no. of rows test::  28\n",
      "no. of columns test::  28\n",
      "Time of execution : 10.622454166412354 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "stime = time.time()\n",
    "filename = {'images' : 'train-images-idx3-ubyte' ,'labels' : 'train-labels-idx1-ubyte','testImages' : 't10k-images-idx3-ubyte' ,'testLabels' : 't10k-labels-idx1-ubyte'}\n",
    "\n",
    "labels_array = np.array([])\n",
    "\n",
    "data_types = {\n",
    "        0x08: ('ubyte', 'B', 1),\n",
    "        0x09: ('byte', 'b', 1),\n",
    "        0x0B: ('>i2', 'h', 2),\n",
    "        0x0C: ('>i4', 'i', 4),\n",
    "        0x0D: ('>f4', 'f', 4),\n",
    "        0x0E: ('>f8', 'd', 8)}\n",
    "\n",
    "for name in filename.keys():\n",
    "    if name == 'images':\n",
    "        imagesfile = open(filename[name],'rb')\n",
    "    if name == 'labels':\n",
    "        labelsfile = open(filename[name],'rb')\n",
    "    if name == 'testImages':\n",
    "        testImagesFile = open(filename[name],'rb')\n",
    "    if name == 'testLabels':\n",
    "        testLabelsFile = open(filename[name],'rb')\n",
    "\n",
    "        \n",
    "def getParams(file):\n",
    "  file.seek(4)\n",
    "  nImg = st.unpack('>I',file.read(4))[0] #num of images/labels\n",
    "  nR = st.unpack('>I',file.read(4))[0] #num of rows\n",
    "  nC = st.unpack('>I',file.read(4))[0] #num of columns\n",
    "  return nImg,nR,nC\n",
    "  \n",
    "#reading magic number\n",
    "imagesfile.seek(0)\n",
    "magic = st.unpack('>4B',imagesfile.read(4))\n",
    "\n",
    "print(magic)\n",
    "if(magic[0] and magic[1])or(magic[2] not in data_types):\n",
    "    raise ValueError(\"File Format not correct\")\n",
    "\n",
    "nDim = magic[3]\n",
    "print(\"Data is \",nDim,\"-D\")\n",
    "\n",
    "\n",
    "nImg,nR,nC= getParams(imagesfile)\n",
    "nBytes = nImg*nR*nC\n",
    "labelsfile.seek(8) #Since no. of items = no. of images and is already read\n",
    "print(\"no. of images :: \",nImg)\n",
    "print(\"no. of rows :: \",nR)\n",
    "print(\"no. of columns :: \",nC)\n",
    "\n",
    "\n",
    "nImgTest,nRTest,nCTest= getParams(testImagesFile)\n",
    "nBytesTest = nImgTest*nRTest*nCTest\n",
    "testLabelsFile.seek(8) #Since no. of items = no. of images and is already read\n",
    "print(\"no. of images test :: \",nImgTest)\n",
    "print(\"no. of rows test:: \",nRTest)\n",
    "print(\"no. of columns test:: \",nCTest)\n",
    "\n",
    "\n",
    "#Read all data bytes at once and then reshape\n",
    "normalizingValue=(255  *0.99 + 0.01)\n",
    "train_imgs = np.asarray(st.unpack('>'+'B'*nBytes,imagesfile.read(nBytes))).reshape((nImg,nR*nC))\n",
    "train_labels = np.asarray(st.unpack('>'+'B'*nImg,labelsfile.read(nImg))).reshape((nImg,1))\n",
    "\n",
    "test_imgs = np.asarray(st.unpack('>'+'B'*nBytesTest,testImagesFile.read(nBytesTest))).reshape((nImgTest,nRTest*nCTest))\n",
    "test_labels = np.asarray(st.unpack('>'+'B'*nImgTest,testLabelsFile.read(nImgTest))).reshape((nImgTest,1))\n",
    "# images_array=np.true_divide(images_array,normalizingValue)\n",
    "# test_images_array=np.true_divide(test_images_array,normalizingValue)\n",
    "\n",
    "\n",
    "lr = np.arange(10)\n",
    "# transform labels into one hot representation\n",
    "train_labels_one_hot = (lr==train_labels).astype(np.float)\n",
    "test_labels_one_hot = (lr==test_labels).astype(np.float)\n",
    "# we don't want zeroes and ones in the labels neither:\n",
    "train_labels_one_hot[train_labels_one_hot==0] = 0.01\n",
    "train_labels_one_hot[train_labels_one_hot==1] = 0.99\n",
    "test_labels_one_hot[test_labels_one_hot==0] = 0.01\n",
    "test_labels_one_hot[test_labels_one_hot==1] = 0.99\n",
    "\n",
    "train_imgs=0.99 - (((0.98) * (255 - train_imgs)) / 255)\n",
    "test_imgs=0.99 - (((0.98) * (255 - test_imgs)) / 255)\n",
    "no_of_different_labels = 10 \n",
    "image_size=28\n",
    "image_pixels = image_size * image_size\n",
    "print(\"Time of execution : %s seconds\" % str(time.time()-stime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uCx_B0IAGhwN"
   },
   "outputs": [],
   "source": [
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.e ** -x)\n",
    "def sigDerivative(x):\n",
    "  return x*(1-x)\n",
    "  \n",
    "activation_function = sigmoid\n",
    "\n",
    "class NeuralNetwork:\n",
    "    \n",
    "    def __init__(self,inNodes, outNodes, hiddenNodes,learningRate,epochs):\n",
    "      self.inNodes = inNodes\n",
    "      self.outNodes = outNodes\n",
    "      self.hiddenNodes = hiddenNodes\n",
    "      self.learningRate = learningRate \n",
    "      self.itohweights=np.random.randn(self.hiddenNodes, self.inNodes)\n",
    "      self.htooweights=np.random.randn(self.outNodes, self.hiddenNodes)\n",
    "      self.xj=[]\n",
    "      self.epochs=epochs\n",
    "        \n",
    "    def forwardPropagation(self,inputVector):\n",
    "      inputVector = np.array(inputVector, ndmin=2).T\n",
    "\n",
    "      output_vector1 = np.dot(self.itohweights, inputVector)\n",
    "      self.xj = sigmoid(output_vector1)\n",
    "\n",
    "      output_vector2 = np.dot(self.htooweights,self.xj)\n",
    "      return sigmoid(output_vector2)\n",
    "      \n",
    "    def backPropagation(self,inputVector,targetVector,expectedVector):\n",
    "        targetVector = np.array(targetVector, ndmin=2).T\n",
    "        inputVector = np.array(inputVector, ndmin=2).T\n",
    "      \n",
    "        errors = targetVector - expectedVector\n",
    "        tmp = errors * sigDerivative(expectedVector )\n",
    "        \n",
    "        self.htooweights += self.learningRate  * np.dot(tmp,self.xj.T)\n",
    "        \n",
    "        # calculate hidden errors:\n",
    "        hidden_errors = np.dot(self.htooweights.T,errors)\n",
    "        # update the weights:\n",
    "        tmp = hidden_errors * sigDerivative(self.xj)\n",
    "        self.itohweights += self.learningRate * np.dot(tmp, inputVector.T)\n",
    "        \n",
    "      \n",
    "    \n",
    "    def train(self, inputVector, targetVector):\n",
    "        for ep in range(self.epochs):\n",
    "          self.backPropagation(inputVector,targetVector,self.forwardPropagation(inputVector))\n",
    "          \n",
    "          \n",
    "    def run(self, inputVector):\n",
    "       \n",
    "        return self.forwardPropagation(inputVector)\n",
    "            \n",
    "    def confusion_matrix(self, data_array, labels):\n",
    "        cm = np.zeros((10, 10), int)\n",
    "        for i in range(len(data_array)):\n",
    "            res = self.run(data_array[i])\n",
    "            res_max = res.argmax()\n",
    "            target = labels[i][0]\n",
    "            cm[res_max, int(target)] += 1\n",
    "        return cm   \n",
    "    def evaluate(self, data, labels):\n",
    "      corrects, wrongs = 0, 0\n",
    "      for i in range(len(data)):\n",
    "          res = self.run(data[i])\n",
    "          res_max = res.argmax()\n",
    "          if res_max == labels[i]:\n",
    "              corrects += 1\n",
    "          else:\n",
    "              wrongs += 1\n",
    "      return corrects, wrongs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NNKMIIb-JgMP"
   },
   "outputs": [],
   "source": [
    "class measuresOfConMatrix:\n",
    "  def __init__(self,cm):\n",
    "    self.cm=cm\n",
    "    self.TP=self.getTP()\n",
    "    self.TN=self.getTN()\n",
    "    self.FP=self.getFP()\n",
    "    self.FN=self.getFN()\n",
    "    self.tot=self.TP+self.TN+self.FP+self.FN\n",
    "  def errorRate(self):\n",
    "    return np.around(((self.FP+self.FN)/self.tot),decimals=3)\n",
    "\n",
    "  def accuracy(self):\n",
    "    return np.around((self.TP+self.TN)/self.tot,decimals=3)\n",
    "\n",
    "  def precision(self):\n",
    "    return np.around((self.TP/(self.TP+self.FP)),decimals=3)\n",
    "  def recall(self):\n",
    "    return np.around((self.TP/(self.TP+self.FN)),decimals=3)\n",
    "  def specificity(self):\n",
    "    return np.around((self.TN/(self.FP+self.TN)),decimals=3)\n",
    "\n",
    "  def getTP(self):\n",
    "        return np.diag(self.cm)\n",
    "  def getFP(self):\n",
    "      FP = []\n",
    "      for i in range(10):\n",
    "        FP.append(sum(self.cm[:,i]) - self.cm[i,i])\n",
    "      return np.array(FP)\n",
    "  def getFN(self):  \n",
    "      FN = []\n",
    "      for i in range(10):\n",
    "          FN.append(sum(self.cm[i,:]) - self.cm[i,i])\n",
    "      return np.array(FN)\n",
    "  def getTN(self):\n",
    "      TN = []\n",
    "      for i in range(10):\n",
    "          temp = np.delete(self.cm, i, 0)   # delete ith row\n",
    "          temp = np.delete(temp, i, 1)  # delete ith column\n",
    "          TN.append(sum(sum(temp)))\n",
    "      return np.array(TN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4ses2A4FfkuK"
   },
   "source": [
    "**5 FoldCross Validation:**\n",
    "\n",
    " In the below we are doing a 5 fold cross validation. The entire data set is divided into 5 equal partions. In each iteration we consider 4 sets as the training sets and remaining set as the test set. Over these training and test sets the model is trained and tested. Each time error is calculated. This is called as the cross validation error. Average is found of these error values.\n",
    " \n",
    " The above process is repeated for different models and the one with the least average error is chosen. This model is then used to train the entire dataset and then test it. \n",
    " \n",
    " This process of cross validations allows us to choose the best model with least average error.\n",
    " \n",
    " In the below code Stochaistic Gradient odel is used with different hyper parameters in each Cross Validation.\n",
    " \n",
    " **Observations:**\n",
    "\n",
    "1.  As the number of hidden unit increases the time taken to execute also increases\n",
    "2.   As the chosen model is Stochaistic Gradient descent, it updates the weight matrix for each of the epoch and hence the time consumed is more.\n",
    "3. The minimum cross validation average error is **0.17968**\n",
    "\n",
    "**Confusion Matrix:**\n",
    "\n",
    "It is a 10 x 10 matrix, where the rows represent the true label of a test sample and the columnsrepresent the predicted labels of the NN classifier\n",
    "\n",
    "There are many measures of Confusion matrix like error, accuracy, standard deviation and many more.\n",
    "\n",
    "TP: True Positive\n",
    "TN: True Negative\n",
    "FP: False Positive\n",
    "FP: False Negative\n",
    "\n",
    "Error = (FP+FN)/(TP+TN+FP+FN)\n",
    "\n",
    "Accuracy = (TP+TN)/(TP+TN+FP+FN)\n",
    "\n",
    "Sensitivity/Recall = TP/(TP+FN)\n",
    "\n",
    "Specificity = TN/(FP+TN)\n",
    "\n",
    "Precision =  TP/(TP+FP)\n",
    "\n",
    "Below are the observations for the best model used\n",
    "Model  Used :  Stochastic Gradient descent Model\n",
    "\n",
    "Hyper Parameters:\n",
    "\n",
    "$\\eta $=0.01, \n",
    "number of hidden layers = 1, \n",
    "number of hidden nodes in one layer = 100, \n",
    "number of epochs = 1\n",
    "\n",
    "**Confusion Matrix obtained:**\n",
    "\n",
    "$\\left[ \\begin{array}{cccc}\n",
    " 930    & 0  & 21  &  8  &  3 &  22  & 20 &   8 &  14&   11 \\\\\n",
    "  0 &1104  &  7  &  4&    5 &   3  &  2 &  13 &  10  &  4\\\\\n",
    " [   8  &  4&  848  & 25 &  12&    6 &  10 &  20  & 14 &   5\\\\\n",
    " [   7  &  9&   33&  875&    0 &  56 &   3   & 8 &  54  & 17\\\\\n",
    " [   1   & 1   &14   & 1 & 848  & 21   &14  & 14  & 18&   71\\\\\n",
    " [   8    &1   & 3   &35   & 2&  693&   13  &  4  & 25  & 15\\\\\n",
    " [  14    &8  & 24  & 13 &  23 &  17&  890 &   4  & 22  &  1\\\\\n",
    " [   4   & 1  & 16  & 12  &  2 &   9   & 0&  884 &   6  & 18\\\\\n",
    " [   6   & 7  & 51 &  22  & 14 &  40  &  6  & 12 & 774  & 17\\\\\n",
    " [   2   & 0  & 15 &  15  & 73  & 25  &  0 &  61   &37 & 850\\\\\n",
    "\\end{array} \\right]$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**Total Accuracy:** 86.96%\n",
    "\n",
    "** Total Error: ** 13.0999%\n",
    "\n",
    "**Average Error of all folds in Cross Validation: **   0.17968\n",
    " \n",
    " \n",
    " **Average Error of digits:** 2.61%\n",
    " **Average Standard Deviation:**  0.00938562730988185\n",
    " \n",
    "\n",
    " | Digit | Precision|Recall|Accuracy | Specificity |Error\n",
    "|------|------|------|------|------|------|\n",
    "| 0 | 0.949 | 0.897 | 0.984 | 0.994 | 0.016 \n",
    "| 1 | 0.973 | 0.958 | 0.992 | 0.996 | 0.008 \n",
    "| 2 | 0.822 | 0.891 | 0.971 | 0.98 | 0.029 \n",
    "| 3 | 0.866 | 0.824 | 0.968 | 0.985 | 0.032 \n",
    "| 4 | 0.864 | 0.845 | 0.971 | 0.985 | 0.029 \n",
    "| 5 | 0.777 | 0.867 | 0.97 | 0.978 | 0.03 \n",
    "| 6 | 0.929 | 0.876 | 0.981 | 0.992 | 0.019 \n",
    "| 7 | 0.86 | 0.929 | 0.979 | 0.984 | 0.021 \n",
    "| 8 | 0.795 | 0.816 | 0.962 | 0.978 | 0.038 \n",
    "| 9 | 0.842 | 0.788 | 0.961 | 0.982 | 0.039"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 799
    },
    "colab_type": "code",
    "id": "BPP6A_87TV3P",
    "outputId": "bc7142a0-a256-4cf2-9973-820d2ed06258"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------START----------------------------------------\n",
      "hiddenNodes :  100 learningRate =  0.01 epochs=  1\n",
      "Error at folds :  [0.17940000000000003, 0.1794, 0.1799, 0.18030000000000002, 0.1794]\n",
      "Average Error :  0.17968\n",
      "-----------------------------------END----------------------------------------\n",
      "-----------------------------------START----------------------------------------\n",
      "hiddenNodes :  100 learningRate =  0.01 epochs=  5\n",
      "Error at folds :  [0.1799, 0.17930000000000001, 0.1801, 0.17950000000000002, 0.18080000000000002]\n",
      "Average Error :  0.17992\n",
      "-----------------------------------END----------------------------------------\n",
      "-----------------------------------START----------------------------------------\n",
      "hiddenNodes :  200 learningRate =  1 epochs=  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: RuntimeWarning: overflow encountered in power\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error at folds :  [0.18209999999999998, 0.1802, 0.1835, 0.1802, 0.1839]\n",
      "Average Error :  0.18197999999999998\n",
      "-----------------------------------END----------------------------------------\n",
      "-----------------------------------START----------------------------------------\n",
      "hiddenNodes :  200 learningRate =  0.01 epochs=  5\n",
      "Error at folds :  [0.17970000000000003, 0.17950000000000005, 0.1814, 0.1798, 0.18080000000000002]\n",
      "Average Error :  0.18024\n",
      "-----------------------------------END----------------------------------------\n",
      "Min Error Index :  0 Min Error :  0.17968\n",
      "Model Used:  [100, 0.01, 1]\n",
      "[[ 930    0   21    8    3   22   20    8   14   11]\n",
      " [   0 1104    7    4    5    3    2   13   10    4]\n",
      " [   8    4  848   25   12    6   10   20   14    5]\n",
      " [   7    9   33  875    0   56    3    8   54   17]\n",
      " [   1    1   14    1  848   21   14   14   18   71]\n",
      " [   8    1    3   35    2  693   13    4   25   15]\n",
      " [  14    8   24   13   23   17  890    4   22    1]\n",
      " [   4    1   16   12    2    9    0  884    6   18]\n",
      " [   6    7   51   22   14   40    6   12  774   17]\n",
      " [   2    0   15   15   73   25    0   61   37  850]]\n",
      "digit:  0 Precision:  0.949 Recall:  0.897 Accuracy:  0.984 Specificity:  0.994 errorRate:  0.016\n",
      "digit:  1 Precision:  0.973 Recall:  0.958 Accuracy:  0.992 Specificity:  0.996 errorRate:  0.008\n",
      "digit:  2 Precision:  0.822 Recall:  0.891 Accuracy:  0.971 Specificity:  0.98 errorRate:  0.029\n",
      "digit:  3 Precision:  0.866 Recall:  0.824 Accuracy:  0.968 Specificity:  0.985 errorRate:  0.032\n",
      "digit:  4 Precision:  0.864 Recall:  0.845 Accuracy:  0.971 Specificity:  0.985 errorRate:  0.029\n",
      "digit:  5 Precision:  0.777 Recall:  0.867 Accuracy:  0.97 Specificity:  0.978 errorRate:  0.03\n",
      "digit:  6 Precision:  0.929 Recall:  0.876 Accuracy:  0.981 Specificity:  0.992 errorRate:  0.019\n",
      "digit:  7 Precision:  0.86 Recall:  0.929 Accuracy:  0.979 Specificity:  0.984 errorRate:  0.021\n",
      "digit:  8 Precision:  0.795 Recall:  0.816 Accuracy:  0.962 Specificity:  0.978 errorRate:  0.038\n",
      "digit:  9 Precision:  0.842 Recall:  0.788 Accuracy:  0.961 Specificity:  0.982 errorRate:  0.039\n",
      "Accuracy :  0.8696 Total Error :  0.13039999999999996 Average error:  0.0261 Average Standar Deviation of Error Rate: 0.00938562730988185\n"
     ]
    }
   ],
   "source": [
    "train_imgs=train_imgs.reshape(nImg,nR*nC)\n",
    "\n",
    "test_imgs=test_imgs.reshape(nImgTest,nRTest*nCTest)\n",
    "numberOfFolds=5\n",
    "hyperParameters=[[100,0.01,1],[100,0.01,5],[200,1,1],[200,0.01,5]]\n",
    "errorTracker=[]\n",
    "stdTracker=[]\n",
    "avgErrorTracker=[]\n",
    "minErrorIndex=0\n",
    "minError=10000\n",
    "\n",
    "for index in range(len(hyperParameters)):\n",
    "  print(\"-----------------------------------START----------------------------------------\")\n",
    "  kfold = KFold(numberOfFolds,False, 1)\n",
    "  print(\"hiddenNodes : \", hyperParameters[index][0], \"learningRate = \",hyperParameters[index][1],\"epochs= \",hyperParameters[index][2])\n",
    "  foldError=[]\n",
    "  stdError=[]\n",
    "  for train, test in kfold.split(train_imgs):\n",
    "    nn = NeuralNetwork(inNodes = image_pixels, outNodes = 10,  hiddenNodes = hyperParameters[index][0], learningRate = hyperParameters[index][1],epochs=hyperParameters[index][2])\n",
    "    trainingSetImg=train_imgs[train]\n",
    "    testingSetImg=train_imgs[test]   \n",
    "    trainingSetLabel=train_labels_one_hot[train]\n",
    "    testingSetLabel=train_labels_one_hot[test]\n",
    "    for k in range(trainingSetImg.shape[0]):\n",
    "      nn.train(trainingSetImg[k], trainingSetLabel[k])\n",
    "    cm = nn.confusion_matrix(testingSetImg, testingSetLabel)\n",
    "\n",
    "    conMatrixMeasures=measuresOfConMatrix(cm)\n",
    "    foldError.append(np.average(conMatrixMeasures.errorRate()))\n",
    "    stdError.append(np.std(conMatrixMeasures.errorRate()))\n",
    "  print(\"Error at folds : \",foldError)\n",
    "  errorTracker.append(foldError)\n",
    "  stdTracker.append(stdError)\n",
    "  avgError=np.average(foldError)\n",
    "  print(\"Average Error : \",avgError)\n",
    "  avgErrorTracker.append(avgError)\n",
    "  if(avgError<minError):\n",
    "    minError=avgError\n",
    "    minErrorIndex=index\n",
    "  print(\"-----------------------------------END----------------------------------------\")\n",
    "   \n",
    "print(\"Min Error Index : \",minErrorIndex,\"Min Error : \",minError)\n",
    "print(\"Model Used: \",hyperParameters[minErrorIndex])    \n",
    "nn = NeuralNetwork(inNodes = image_pixels, outNodes = 10,  hiddenNodes = hyperParameters[minErrorIndex][0], learningRate = hyperParameters[minErrorIndex][1],epochs=hyperParameters[minErrorIndex][2])   \n",
    "for i in range(train_imgs.shape[0]):\n",
    "  nn.train(train_imgs[i],train_labels_one_hot[i])\n",
    "cm=nn.confusion_matrix(test_imgs, test_labels)\n",
    "print(cm)\n",
    "conMatrixMeasures=measuresOfConMatrix(cm)\n",
    "corrects, wrongs = nn.evaluate(test_imgs, test_labels)\n",
    "accuracy=corrects / ( corrects + wrongs)\n",
    "for i in range(10):\n",
    "  print(\"digit: \", i, \"Precision: \", conMatrixMeasures.precision()[i], \"Recall: \", conMatrixMeasures.recall()[i],\n",
    "       \"Accuracy: \", conMatrixMeasures.accuracy()[i], \"Specificity: \", conMatrixMeasures.specificity()[i],\n",
    "       \"errorRate: \",conMatrixMeasures.errorRate()[i])\n",
    "print(\"Accuracy : \",accuracy,\"Total Error : \",1-accuracy,\"Average error: \",np.average(conMatrixMeasures.errorRate()),\"Average Standar Deviation of Error Rate:\",np.std(conMatrixMeasures.errorRate()));\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 717
    },
    "colab_type": "code",
    "id": "V7VqiYWOUKCH",
    "outputId": "37411c6e-8634-4844-e329-cd60b00c3a84"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error at each fold : [0.17940000000000003, 0.1794, 0.1799, 0.18030000000000002, 0.1794]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe8AAAFOCAYAAACvyZWGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff58380d198>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard Deviation Error at each fold : [0.23905990880948647, 0.23940726806009877, 0.23994768179751189, 0.24068944721362423, 0.2392618649095589]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAecAAAFLCAYAAADs00TBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAE4ZJREFUeJzt3WFonfX99/FP2qw4SeYSm5O6aakU\npZJRRsGyLaXdJFXaOW62MY3DVpgIBUurLGMjYlPQFi3eZdQHE1zHkD1YoATpDYOW9V9BarT6pMNu\nMFskRJnNSY3BUJUqvR8Mzta/Nkn11PNr+no9ypXr/JLf+dL2nVxXc9J07ty5cwEAijGv0RsAAM4n\nzgBQGHEGgMKIMwAURpwBoDDiDACFaZ7Ng3bu3Jljx46lqakp/f39Wb58ee3cyy+/nN27d2fevHm5\n8cYbs2PHjrz66qvZunVrbrrppiTJzTffnEcfffTSPAMAmGNmjPPRo0czMjKSwcHBnDx5Mv39/Rkc\nHKyd37ZtW5577rksWrQoW7ZsyYsvvpirrroqK1euzJ49e2a9kWr1/c/3DArX1nZ1JibONHobc4Z5\n1p+Z1p+Z1tdcnWdHR+sFz814WXt4eDg9PT1JkqVLl2ZycjJTU1O180NDQ1m0aFGSpL29PRMTE190\nv3NKc/P8Rm9hTjHP+jPT+jPT+roS5zljnMfHx9PW1lY7bm9vT7VarR23tLQkScbGxnLkyJGsWbMm\nSXLixIls2rQp99xzT44cOVLvfQPAnDWre87/7bNe7fP06dPZtGlTBgYG0tbWliVLlmTz5s1Zt25d\nRkdHs3Hjxhw8eDALFiy44Mdta7t6zn51NN2lCy6eedafmdafmdbXlTbPGeNcqVQyPj5eOx4bG0tH\nR0fteGpqKg888EAeeuihrFq1KknS2dmZ9evXJ0kWL16chQsX5tSpU7nhhhsu+Hnm4v2E5N9/oObq\n/fRGMM/6M9P6M9P6mqvz/EL3nLu7u3PgwIEkyfHjx1OpVGqXspPkiSeeyH333ZfVq1fX3rd///7s\n3bs3SVKtVnP69Ol0dnZ+7icAAFeSGb9zXrFiRbq6utLb25umpqYMDAxkaGgora2tWbVqVZ5//vmM\njIxk3759SZI777wzP/zhD9PX15dDhw7l7Nmz2b59+7SXtAGA/2gq5VdGzsVLFsncvRzTKOZZf2Za\nf2ZaX3N1nl/osjYA8OUSZwAojDgDQGHEGQAKI84AUBhxBoDCXPTLdwKU6hdP/E+jt1CMP/zmtkZv\ngS9AnKFBhOR8YgL/MWfj7B++89XjHz4z/Q8h4Urg7/z5vsy/9+45A0BhxBkACiPOAFAYcQaAwogz\nABRGnAGgMOIMAIURZwAojDgDQGHEGQAKI84AUBhxBoDCiDMAFEacAaAw4gwAhRFnACiMOANAYcQZ\nAAojzgBQGHEGgMKIMwAURpwBoDDiDACFEWcAKIw4A0BhxBkACiPOAFAYcQaAwogzABRGnAGgMOIM\nAIURZwAojDgDQGHEGQAKI84AUBhxBoDCiDMAFEacAaAw4gwAhRFnACiMOANAYZpn86CdO3fm2LFj\naWpqSn9/f5YvX1479/LLL2f37t2ZN29ebrzxxuzYsSPz5s2bdg0AcGEzxvno0aMZGRnJ4OBgTp48\nmf7+/gwODtbOb9u2Lc8991wWLVqULVu25MUXX8xXv/rVadcAABc242Xt4eHh9PT0JEmWLl2aycnJ\nTE1N1c4PDQ1l0aJFSZL29vZMTEzMuAYAuLAZ4zw+Pp62trbacXt7e6rVau24paUlSTI2NpYjR45k\nzZo1M64BAC5sVvec/9u5c+c+9b7Tp09n06ZNGRgYOC/K063539rark5z8/yL3Q6z1NHR2ugtzCnm\nWX9mWl/mWX9f5kxnjHOlUsn4+HjteGxsLB0dHbXjqampPPDAA3nooYeyatWqWa35LBMTZy5688xe\ntfp+o7cwp5hn/ZlpfZln/dV7ptPFfsbL2t3d3Tlw4ECS5Pjx46lUKrVL2UnyxBNP5L777svq1atn\nvQYAuLAZv3NesWJFurq60tvbm6ampgwMDGRoaCitra1ZtWpVnn/++YyMjGTfvn1JkjvvvDN33333\np9YAALMzq3vOfX195x0vW7as9vbrr78+qzUAwOx4hTAAKIw4A0BhxBkACiPOAFAYcQaAwogzABRG\nnAGgMOIMAIURZwAojDgDQGHEGQAKI84AUBhxBoDCiDMAFEacAaAw4gwAhRFnACiMOANAYcQZAAoj\nzgBQGHEGgMKIMwAURpwBoDDiDACFEWcAKIw4A0BhxBkACiPOAFAYcQaAwogzABRGnAGgMOIMAIUR\nZwAojDgDQGHEGQAKI84AUBhxBoDCiDMAFEacAaAw4gwAhRFnACiMOANAYcQZAAojzgBQGHEGgMKI\nMwAURpwBoDDiDACFEWcAKIw4A0BhxBkACtM8mwft3Lkzx44dS1NTU/r7+7N8+fLauY8++ijbtm3L\nG2+8kaGhoSTJK6+8kq1bt+amm25Kktx888159NFHL8H2AWDumTHOR48ezcjISAYHB3Py5Mn09/dn\ncHCwdn7Xrl255ZZb8sYbb5y3buXKldmzZ0/9dwwAc9yMl7WHh4fT09OTJFm6dGkmJyczNTVVO//w\nww/XzgMAX9yM3zmPj4+nq6urdtze3p5qtZqWlpYkSUtLS957771PrTtx4kQ2bdqUycnJbN68Od3d\n3dN+nra2q9PcPP9i988sdXS0NnoLc4p51p+Z1pd51t+XOdNZ3XP+b+fOnZvxMUuWLMnmzZuzbt26\njI6OZuPGjTl48GAWLFhwwTUTE2cuditchGr1/UZvYU4xz/oz0/oyz/qr90yni/2Ml7UrlUrGx8dr\nx2NjY+no6Jh2TWdnZ9avX5+mpqYsXrw4CxcuzKlTpy5iywBw5Zoxzt3d3Tlw4ECS5Pjx46lUKrVL\n2heyf//+7N27N0lSrVZz+vTpdHZ21mG7ADD3zXhZe8WKFenq6kpvb2+ampoyMDCQoaGhtLa2Zu3a\ntdmyZUveeeedvPnmm9mwYUPuuuuu3Hbbbenr68uhQ4dy9uzZbN++fdpL2gDAf8zqnnNfX995x8uW\nLau9faEfl3rmmWe+wLYA4MrlFcIAoDDiDACFEWcAKIw4A0BhxBkACiPOAFAYcQaAwogzABRGnAGg\nMOIMAIURZwAojDgDQGHEGQAKI84AUBhxBoDCiDMAFEacAaAw4gwAhRFnACiMOANAYcQZAAojzgBQ\nGHEGgMKIMwAURpwBoDDiDACFEWcAKIw4A0BhxBkACiPOAFAYcQaAwogzABRGnAGgMOIMAIURZwAo\njDgDQGHEGQAKI84AUBhxBoDCiDMAFEacAaAw4gwAhRFnACiMOANAYcQZAAojzgBQGHEGgMKIMwAU\nRpwBoDDiDACFmVWcd+7cmbvvvju9vb3529/+dt65jz76KL/+9a/zk5/8ZNZrAIALmzHOR48ezcjI\nSAYHB7Njx47s2LHjvPO7du3KLbfcclFrAIALmzHOw8PD6enpSZIsXbo0k5OTmZqaqp1/+OGHa+dn\nuwYAuLDmmR4wPj6erq6u2nF7e3uq1WpaWlqSJC0tLXnvvfcuas1naWu7Os3N8y/6CTA7HR2tjd7C\nnGKe9Wem9WWe9fdlznTGOP9v586du+hPMps1ExNnLvrjMnvV6vuN3sKcYp71Z6b1ZZ71V++ZThf7\nGS9rVyqVjI+P147HxsbS0dFR9zUAwL/NGOfu7u4cOHAgSXL8+PFUKpVpL09/3jUAwL/NeFl7xYoV\n6erqSm9vb5qamjIwMJChoaG0trZm7dq12bJlS9555528+eab2bBhQ+6666786Ec/+tQaAGB2ZnXP\nua+v77zjZcuW1d7es2fPrNYAALPjFcIAoDDiDACFEWcAKIw4A0BhxBkACiPOAFAYcQaAwogzABRG\nnAGgMOIMAIURZwAojDgDQGHEGQAKI84AUBhxBoDCiDMAFEacAaAw4gwAhRFnACiMOANAYcQZAAoj\nzgBQGHEGgMKIMwAURpwBoDDiDACFEWcAKIw4A0BhxBkACiPOAFAYcQaAwogzABRGnAGgMOIMAIUR\nZwAojDgDQGHEGQAKI84AUBhxBoDCiDMAFEacAaAw4gwAhRFnACiMOANAYcQZAAojzgBQGHEGgMKI\nMwAURpwBoDDiDACFaZ7Ng3bu3Jljx46lqakp/f39Wb58ee3cSy+9lN27d2f+/PlZvXp1Hnzwwbzy\nyivZunVrbrrppiTJzTffnEcfffTSPAMAmGNmjPPRo0czMjKSwcHBnDx5Mv39/RkcHKydf/zxx7N3\n7950dnbm3nvvzR133JEkWblyZfbs2XPpdg4Ac9SMl7WHh4fT09OTJFm6dGkmJyczNTWVJBkdHc01\n11yT6667LvPmzcuaNWsyPDx8aXcMAHPcjHEeHx9PW1tb7bi9vT3VajVJUq1W097e/pnnTpw4kU2b\nNuWee+7JkSNH6r1vAJizZnXP+b+dO3duxscsWbIkmzdvzrp16zI6OpqNGzfm4MGDWbBgwQXXtLVd\nnebm+Re7HWapo6O10VuYU8yz/sy0vsyz/r7Mmc4Y50qlkvHx8drx2NhYOjo6PvPcqVOnUqlU0tnZ\nmfXr1ydJFi9enIULF+bUqVO54YYbLvh5JibOfO4nwcyq1fcbvYU5xTzrz0zryzzrr94znS72M17W\n7u7uzoEDB5Ikx48fT6VSSUtLS5Lk+uuvz9TUVN566618/PHHOXz4cLq7u7N///7s3bs3yb8vfZ8+\nfTqdnZ31eC4AMOfN+J3zihUr0tXVld7e3jQ1NWVgYCBDQ0NpbW3N2rVrs3379vzyl79Mkqxfvz43\n3nhjOjo60tfXl0OHDuXs2bPZvn37tJe0AYD/mNU9576+vvOOly1bVnv71ltvPe9Hq5KkpaUlzzzz\nTB22BwBXHq8QBgCFEWcAKIw4A0BhxBkACiPOAFAYcQaAwogzABRGnAGgMOIMAIURZwAojDgDQGHE\nGQAKI84AUBhxBoDCiDMAFEacAaAw4gwAhRFnACiMOANAYcQZAAojzgBQGHEGgMKIMwAURpwBoDDi\nDACFEWcAKIw4A0BhxBkACiPOAFAYcQaAwogzABRGnAGgMOIMAIURZwAojDgDQGHEGQAKI84AUBhx\nBoDCiDMAFEacAaAw4gwAhRFnACiMOANAYcQZAAojzgBQGHEGgMKIMwAURpwBoDDiDACFEWcAKEzz\nbB60c+fOHDt2LE1NTenv78/y5ctr51566aXs3r078+fPz+rVq/Pggw/OuAYAuLAZ43z06NGMjIxk\ncHAwJ0+eTH9/fwYHB2vnH3/88ezduzednZ259957c8cdd+Tdd9+ddg0AcGEzxnl4eDg9PT1JkqVL\nl2ZycjJTU1NpaWnJ6Ohorrnmmlx33XVJkjVr1mR4eDjvvvvuBdcAANOb8Z7z+Ph42traasft7e2p\nVqtJkmq1mvb29k+dm24NADC9Wd1z/m/nzp276E8ymzUdHa0X/XGn8//+7/+p68fDTOvNPOvPTOvL\nPBtnxjhXKpWMj4/XjsfGxtLR0fGZ506dOpVKpZKvfOUrF1wDAExvxsva3d3dOXDgQJLk+PHjqVQq\ntXvH119/faampvLWW2/l448/zuHDh9Pd3T3tGgBgek3nZnHN+amnnsprr72WpqamDAwM5O9//3ta\nW1uzdu3avPrqq3nqqaeSJLfffnvuv//+z1yzbNmyS/tMAGCOmFWcAYAvj1cIA4DCiDMAFEacL6F/\n/vOf6enpyZ/+9KdGb2VO2LVrV+6+++789Kc/zcGDBxu9ncveBx98kK1bt+bee+/Nz372sxw+fLjR\nW5oTPvzww/T09GRoaKjRW7nsvfLKK/nOd76TDRs2ZMOGDXnssccavaUvzUX/nDOzc+bMmTz22GP5\n7ne/2+itzAkvv/xy3njjjQwODmZiYiI//vGPc/vttzd6W5e1w4cP51vf+lYeeOCBvP322/nFL36R\nH/zgB43e1mXvd7/7Xa655ppGb2POWLlyZfbs2dPobXzpxPkSWbBgQZ599tk8++yzjd7KnHDrrbfW\nfnnK1772tXzwwQf55JNPMn/+/Abv7PK1fv362tv/+te/0tnZ2cDdzA0nT57MiRMn8v3vf7/RW+Ey\n57L2JdLc3Jyrrrqq0duYM+bPn5+rr746SbJv376sXr1amOukt7c3fX196e/vb/RWLntPPvlkfvOb\n3zR6G3PKiRMnsmnTptxzzz05cuRIo7fzpfGdM5eVv/71r9m3b1/+8Ic/NHorc8af//zn/OMf/8iv\nfvWr7N+/P01NTY3e0mXp+eefz7e//e3ccMMNjd7KnLFkyZJs3rw569aty+joaDZu3JiDBw9mwYIF\njd7aJSfOXDZefPHFPPPMM/n973+f1tb6vhb7lej111/Ptddem+uuuy633HJLPvnkk7z77ru59tpr\nG721y9ILL7yQ0dHRvPDCC3nnnXeyYMGCLFq0KN/73vcavbXLVmdnZ+32y+LFi7Nw4cKcOnXqivgC\nSJy5LLz//vvZtWtX/vjHP+brX/96o7czJ7z22mt5++2388gjj2R8fDxnzpw577fJcXF++9vf1t5+\n+umn881vflOYv6D9+/enWq3m/vvvT7VazenTp6+Y/xshzpfI66+/nieffDJvv/12mpubc+DAgTz9\n9NPC8jn95S9/ycTERB566KHa+5588sl84xvfaOCuLm+9vb155JFH8vOf/zwffvhhtm3blnnz/DcU\nynHbbbelr68vhw4dytmzZ7N9+/Yr4pJ24uU7AaA4vkwGgMKIMwAURpwBoDDiDACFEWcAKIw4A0Bh\nxBkACiPOAFCY/w9aEQ0q3MCByQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff5835a1550>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x=np.arange(1,numberOfFolds+1,1)\n",
    "print(\"Error at each fold :\",errorTracker[minErrorIndex])\n",
    "plt.bar(x,errorTracker[minErrorIndex])\n",
    "plt.xlim(0,6)\n",
    "plt.ylim(0.15,0.185)\n",
    "plt.show()\n",
    "print(\"Standard Deviation Error at each fold :\",stdTracker[minErrorIndex])\n",
    "\n",
    "plt.bar(x,stdTracker[minErrorIndex])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AN0aYof-Cdwn"
   },
   "source": [
    "** K Nearest Neighbour:**\n",
    "\n",
    "This is a classifier that does not require any training.\n",
    " The prediction is done by calculating the eucledian distance. The 1 nearest neighbour that is closest is considered to be the class of the data point.\n",
    " \n",
    " Eucledian Distance is claculated as $\\sqrt{(x1-x2)^2+(y1-y2)^2}$\n",
    " \n",
    " \n",
    " This is the simplest model that can be iplemented, but the drawback is the time taken to claculate. It has to find the distance between the given point and all the training set and then sort these distances to find the minimum. \n",
    " \n",
    " **Note:** As it takes a lot of time, only 1st 100 test data is considered.\n",
    " \n",
    " \n",
    " **Accuracy:** \n",
    " \n",
    "**Observation:**\n",
    "\n",
    "1. The accuracy of 1 NN Classifierr is than MLFFNN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AofS44zF6gWH"
   },
   "outputs": [],
   "source": [
    "train_imgs=train_imgs.reshape(nImg,nR,nC)\n",
    "test_imgs=test_imgs.reshape(nImgTest,nRTest,nCTest)\n",
    "\n",
    "class NearestNeighborClassifier(object):\n",
    "    \n",
    "    def __init__(self, dataset, k):\n",
    "        self.dataset = dataset\n",
    "        self.k = k\n",
    "        \n",
    "    def predict(self, point):\n",
    "#       candidates = self.dataset[:]\n",
    "\n",
    "#       neighbors = []\n",
    "#       while len(neighbors) < self.k:\n",
    "#           distances = [self.distance(x[0], point) for x in candidates]\n",
    "#           best_distance = min(distances)\n",
    "#           index = distances.index(best_distance)\n",
    "#           neighbors.append(candidates[index])\n",
    "#           del candidates[index]\n",
    "\n",
    "#       prediction = self.consensus([value[1] for value in neighbors])\n",
    "#       return prediction\n",
    "        distances = [self.distance(x[0], point) for x in self.dataset]\n",
    "        # Naive approach: sort based on distances, take the first k elements.\n",
    "        values = sorted(zip(distances, self.dataset),key = lambda val: val[0])\n",
    "#         values.sort(key = lambda val: val[0])\n",
    "        # Predict by averaging the closets k elements.\n",
    "        prediction = self.consensus([value[1][1] for value in values[0:k]])\n",
    "        return prediction\n",
    "        \n",
    "def euclidean_distance(img1, img2):\n",
    "    return np.sum((img1-img2)**2)\n",
    "  \n",
    "  \n",
    "from collections import defaultdict\n",
    "def get_majority(votes):\n",
    "    # For convenience, we're going to use a defaultdict.\n",
    "    # This is just a dictionary where values are initialized to zero\n",
    "    # if they don't exist\n",
    "    print(votes)\n",
    "    counter = defaultdict(int)\n",
    "    for vote in votes:\n",
    "        # If this weren't a defaultdict, this would error on new vote values.\n",
    "#         counter[vote] += 1\n",
    "#         print(vote[0])\n",
    "        counter[vote[0]] += 1\n",
    "    \n",
    "    \n",
    "    # Find out who was the majority.\n",
    "    majority_count = max(counter.values())\n",
    "    for key, value in counter.items():\n",
    "        if value == majority_count:\n",
    "            return key\n",
    "          \n",
    "          \n",
    "class MNISTPredictor(NearestNeighborClassifier):\n",
    "    def distance(self, p1, p2):\n",
    "        return euclidean_distance(p1, p2)\n",
    "    \n",
    "    def consensus(self, values):\n",
    "#         print(values)\n",
    "        return get_majority(values)\n",
    "    \n",
    "# Convert our data set into an easy format to use.\n",
    "# This is a list of (x, y) pairs. x is an image, y is a label.\n",
    "dataset = []\n",
    "for i in range(len(train_imgs)):\n",
    "    dataset.append((train_imgs[i, :, :], train_labels[i]))\n",
    "    \n",
    "# Create a predictor for various values of k.\n",
    "ks = [1]\n",
    "predictors = [MNISTPredictor(dataset, k) for k in ks] \n",
    "\n",
    "def predict_test_set(predictor, test_set):\n",
    "    \"\"\"Compute the prediction for every element of the test set.\"\"\"\n",
    "    predictions = [predictor.predict(test_set[i, :, :]) \n",
    "                   for i in range(len(test_set))]\n",
    "    return predictions\n",
    "\n",
    "# Choose a subset of the test set. Otherwise this will never finish.\n",
    "test_set = test_imgs[0:100, :, :]\n",
    "all_predictions = [predict_test_set(predictor, test_set) for predictor in predictors]\n",
    "\n",
    "def evaluate_prediction(predictions, answers):\n",
    "    \"\"\"Compute how many were identical in the answers and predictions,\n",
    "    and divide this by the number of predictions to get a percentage.\"\"\"\n",
    "    correct = sum(asarray(predictions) == asarray(answers))\n",
    "    total = float(prod(answers.shape))\n",
    "    return correct / total\n",
    "\n",
    "labels = asarray(test_labels[0:100])\n",
    "accuracies = [evaluate_prediction(pred, labels) for pred in all_predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "kr8HWczd19-S",
    "outputId": "246fb25f-ea0f-4bc6-c440-5ed9e4007df6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Final.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
